{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for (0, 'W')\n",
      "Gradients are different at (0, 0). Analytic: 0.00002, Numeric: 0.00001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for (0, 'W')\n",
      "Gradients are different at (0, 1). Analytic: -0.00123, Numeric: -0.00118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.985179, Train accuracy: 0.359778, val accuracy: 0.361000\n",
      "Loss: 2.369761, Train accuracy: 0.557444, val accuracy: 0.545000\n",
      "Loss: 2.721862, Train accuracy: 0.569444, val accuracy: 0.557000\n",
      "Loss: 3.548311, Train accuracy: 0.654667, val accuracy: 0.636000\n",
      "Loss: 3.615570, Train accuracy: 0.685000, val accuracy: 0.645000\n",
      "Loss: 3.569147, Train accuracy: 0.724222, val accuracy: 0.671000\n",
      "Loss: 4.004584, Train accuracy: 0.719444, val accuracy: 0.678000\n",
      "Loss: 4.133325, Train accuracy: 0.725667, val accuracy: 0.661000\n",
      "Loss: 4.849701, Train accuracy: 0.720000, val accuracy: 0.647000\n",
      "Loss: 5.094152, Train accuracy: 0.733000, val accuracy: 0.667000\n",
      "Loss: 5.715943, Train accuracy: 0.749444, val accuracy: 0.706000\n",
      "Loss: 5.619437, Train accuracy: 0.753556, val accuracy: 0.684000\n",
      "Loss: 5.678403, Train accuracy: 0.784444, val accuracy: 0.704000\n",
      "Loss: 6.041727, Train accuracy: 0.766667, val accuracy: 0.680000\n",
      "Loss: 6.405663, Train accuracy: 0.746111, val accuracy: 0.679000\n",
      "Loss: 6.357599, Train accuracy: 0.773111, val accuracy: 0.697000\n",
      "Loss: 6.787427, Train accuracy: 0.779222, val accuracy: 0.700000\n",
      "Loss: 7.095277, Train accuracy: 0.701111, val accuracy: 0.641000\n",
      "Loss: 6.783399, Train accuracy: 0.770444, val accuracy: 0.679000\n",
      "Loss: 7.679484, Train accuracy: 0.740444, val accuracy: 0.651000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 0.01)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 0.01)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5efe7263d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)\n",
    "plt.plot([i/100 for i in loss_history])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.906977, Train accuracy: 0.362556, val accuracy: 0.375000\n",
      "Loss: 1.673692, Train accuracy: 0.576444, val accuracy: 0.574000\n",
      "Loss: 2.181144, Train accuracy: 0.582667, val accuracy: 0.548000\n",
      "Loss: 0.773368, Train accuracy: 0.659778, val accuracy: 0.624000\n",
      "Loss: 1.107633, Train accuracy: 0.690000, val accuracy: 0.644000\n",
      "Loss: 2.128651, Train accuracy: 0.695889, val accuracy: 0.662000\n",
      "Loss: 0.668363, Train accuracy: 0.756000, val accuracy: 0.699000\n",
      "Loss: 1.044617, Train accuracy: 0.753222, val accuracy: 0.682000\n",
      "Loss: 1.248500, Train accuracy: 0.756778, val accuracy: 0.690000\n",
      "Loss: 0.511209, Train accuracy: 0.786778, val accuracy: 0.717000\n",
      "Loss: 0.445406, Train accuracy: 0.775778, val accuracy: 0.690000\n",
      "Loss: 0.570236, Train accuracy: 0.797889, val accuracy: 0.717000\n",
      "Loss: 0.827501, Train accuracy: 0.798778, val accuracy: 0.700000\n",
      "Loss: 0.403548, Train accuracy: 0.814222, val accuracy: 0.708000\n",
      "Loss: 0.860911, Train accuracy: 0.783000, val accuracy: 0.688000\n",
      "Loss: 0.654519, Train accuracy: 0.824222, val accuracy: 0.712000\n",
      "Loss: 0.845165, Train accuracy: 0.835778, val accuracy: 0.728000\n",
      "Loss: 0.318798, Train accuracy: 0.862333, val accuracy: 0.737000\n",
      "Loss: 0.877651, Train accuracy: 0.842889, val accuracy: 0.719000\n",
      "Loss: 0.450631, Train accuracy: 0.867111, val accuracy: 0.718000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 0)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5efe637090>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqMklEQVR4nO3deXxU12H28d8ZbWhBEiAhAUKI3WZfxGJw8ArYrpfEcbwkcb3EdVPHbdqmSd00Tf2mTZutSfrmddM4iXc7tvEW4uDYxHHiBbARm7EAgwAhxCokIbQhaWbO+8cZiZGQhECaGenyfPnMZ+5y5t6jy+i5R+duxlqLiIgMfL5YV0BERPqGAl1ExCMU6CIiHqFAFxHxCAW6iIhHxMdqxVlZWbagoCBWqxcRGZA2bNhwzFqb3dm8mAV6QUEBRUVFsVq9iMiAZIzZ19U8dbmIiHiEAl1ExCMU6CIiHqFAFxHxCAW6iIhHKNBFRDxCgS4i4hEKdBGRKNldUcePVu/k48O1EVl+zC4sEhGJtuMNzfxpZwXjs9OYMiIdn89EfJ0Hjjfy6paDrNxykOKDJzAGsgYnMTl3cJ+vS4EuIp4WCFre2VXBiqJyVm87QnMgCEBWWiIXT8jiksnZfGJiNllpSX22zmN1TazaeoiVmw9StK8agJmjM/mXa6dw7YwR5KQP6rN1hVOgi4gn7T1Wz4qi/by08QCHT5wkMyWBzy7I57qZI9hX2cDbOyt4e9cxXtl8EICpI9NZMimbSyZlMyd/CInxZ9cjXdPYwuvFh/nNloOs2V1JIGiZnDOYry6fzLUzRjBmWGokfsx2TKweQVdYWGh1LxcR6Uv1TX5+u/UQK4r2s760Gp+BSyZl85nC0Vxx4XCS4uPalQ8GLcUHT/D2rgr+9HEFG8uq8QctqYlxXDTetd4vmZhN/rCUTtfX2BzgzR1HWLn5IH/8uILmQJD8oSlcN3ME188cFZFuFWPMBmttYafzFOgiMpBZa1lfWs3zRftZtfUQDc0BxmWlclNhHjfOziM3o+fdG7UnW1izu5K3d1bwp50VlFc3AlAwLIVLJmWzZFI2hWOGUrSvipVbDrJ62xEamgMMH5zEtTNGcv2skczMy8CYyPXNK9BFxHMO1TTy4oZyXthQTmllA6mJcVw7YySfKcxj7pghvQ5Vay17j9W3hfu6PVU0tgTa5memJHD1tBFcN3MEC8YOIy4KB1ih+0BXH7qIDAj+QJCyqgY+LK/hpU0HeHdXBUELC8YO5f7LJ3LN9FxSEvsu0owxjMtOY1x2GncuHkuTP0BRaTUb9lUzbVQ6F0/IPut+9khToItIv9ISCLKvsp5dR+rYdbSOnUdqKTlax56K+rYzVEZmDOJLl03gprl5UTnYCJAUH8fiCVksnpAVlfWdCwW6iMREsz9IaVtw17a97z1WT0vgVFfw6KHJTBw+mEsmZTMxZzCTctKYOjIjal0cA4kCXUSi5uPDtfzPH0soPniC0mP1+IMuuI2B/KEpTByexuUX5DApJ42Jwwczfnhqn3ajeJ22lIhEXE1jCz9avZMn1+0jNTGOBeOGsXxqDhOHD2bC8DQmDE9jUELcmRck3VKgi5wngkFLSUUdu4/WcdH4YWSmJEZlnc8X7ed7r3/M8YZmPrsgn68sncyQ1Miv+3zUo0A3xlwF/DcQB/zCWvudDvPzgceBzFCZB6y1q/q2qiJyNmoaWti4v5pNZcfZVFbN5rLj1Db5AUhOiOPmwjzuWjyWgqzIHFTcVFbNgyuL2VJeQ+GYITx4/XymjcqIyLrEOWOgG2PigIeApUA5sN4Ys9Jauy2s2DeA5621PzXGTAFWAQURqK+IdCIQtOw6WsvGfcfZWFbNprJqdlfUA+AzMDk3netmjWRO/hBGZSbzwoZynvmgjCfW7WPZlBzu+cQ4Cvvg3G2Aitomvve7HazYUM7wwUn8+JZZ3DBrZEQvthGnJy30+UCJtXYPgDHmWeAGIDzQLZAeGs4ADvZlJUWkver6ZjaFWt8by6rZsr+GulDre2hqIrNHZ3LjnDxm52cyIy+TtKT2v+oXjR/GP141mcfXlvLUujJeLz7CzNGZ3HPxWK6elkt83NmfX90SCPLE2n38ePVOTvoD/OUl4/jryyeetm6JnDNeKWqMuQm4ylp7T2j8dmCBtfb+sDIjgDeAIUAqcKW1dkN3y9WVonK+OXGyhbd2HGXt7koaWwIEgrbtFbTu3R823Payri/aH7QEg5aGFj/7q9wl6XE+wwW5g5mTP4Q5YzKZPXoIY4alnFVruKHZz4sbyvnlu3sprWxgVGYydy0u4OZ5o0kflNCjZawpOcaDvylm55E6lkzK5l+vm8L47LRz2k7SvV5d+t/DQP/70LL+yxhzEfBLYJq1NthhWfcC9wLk5+fP3bdvXy9+LJH+72jtSVZvO8LrxUdYu/sYLQHLkJQEMpIT8PkMccYQ5zv18oWPh4ZdOYjz+YjzQWJ8HBeOcCE+Iy+jz07rCwYtb+44ys/f2cMHe6tIS4rn1nmjuXNxAXlDOr851YHjjXz7t9tYtfUwo4cm8y9/NoWlU3LUvRJBvQ30i4AHrbXLQ+P/BGCt/c+wMsW40N8fGt8DLLTWHu1quWqhS6w0NgcYlOCLWOjsq6zn9eLDvF58hI1l1Vjrbu60fGouy6bmMnt0ZlQerNAbH5Yf55fv7uXVDw8BcPW0XO75xDhmjc4E4GRLgIff3sP//LEEgPsuncC9S8bp1MMo6G2gxwM7gSuAA8B64LPW2uKwMq8Bz1lrHzPGXAi8CYyy3SxcgS7RFAha/rDjKI+t2ct7JZVkJCcwPjuV8dlpjB+exoTQ++ghyWfdf2ytZduhE7xefIQ3ig+zI/R4sakj01k+NZflU3OZlJM2IFutB4838tiaUn71fhm1TX7mFQxh+dRcnli7j7KqBq6ZnsvXr7mwyxa89L1e323RGHMN8GPcKYmPWGu/bYz5FlBkrV0ZOrPl50Aa7gDp16y1b3S3TAW6RENNYwsrivbz+NpS9lc1MjJjEJ+cPYqaxhZ2V9Sxu6KeitqmtvKJcT4KslJc0Ge7C17GZ6cxLjuV1LCDe4GgZcO+6lBL/DDl1Y0YA/PGDGX5tFyWTclh9FDvhFxdk5/n1+/nkff2Ul7dyMThaTx4/dR+fV8Tr9Ltc+W8s+tILY+vLeXFDQdobAkwf+xQ7lpUwNIpOae1wGsaWth9zF1w4y68qWd3RR1lVQ0Egqd+P0ZmDGL88DSGpCSyZvcxjtU1kxjnY/GEYSyfmsuVU3L69DFm/ZE/EGTH4Vom5w4m4RzOhJHe0+1z5bwQCFre2nGUx9aU8m7JMRLjfXxy1kjuWFTA1JFdX9CSkZLgzhLJH9JuepM/QFllAyVH69pa8yVH6/j4cC0Lx7kQv3RyNoN7eCaIF8TH+XRxUD+mQJcBr7VbpbVfNzd9EF9dPpnb5ucztBeXmCfFxzExZzATc/r+MWIikaBAlwGr5Ggdj68p5cWN5TQ0B5hXMIR/vOoClk3NUXeAnJcU6HLWAkGLzxC1szaCQUt9s5/6pgB1TX72VNTx5Lp9vLPrGIlxPq6fNZI7FxWoK0DOewp06TFrLQ+9VcJ/v7mLoHU3eEpOjHPvCXEMSowjOcFHSmK8G0+IIznRFyoXHyrnIyHeR2OzC+f6Jj91TQHq24b97cK7vslPQ3PgtLrkpCfxD8smcev8fM8fiBTpKQW69EizP8jXX97KCxvKWTYlh4k5aTQ2B2lsCdDY7HfvLUFONgeoqG0KTQ+0e+9MckIcqUnxpCW599SkeIYPHkRqVmhaYnxofnxofhzDUpNYMG6oulVEOlCgyxnVNLTwxac2sHZPJX975US+fMXEs+5usdbS5A/S2BygyR8kJRTWeoyYSN9RoEu3yiobuOuxDyirauBHt8zkU7Pzzmk5xhgGhbphRCQyFOjSpY1l1fzF40X4g5anvrCABeOGxbpKImfH3ww1+6G6FI7vg+p9UHsYhl8AY5fAiFng804jQ4EunVq19RB/99xmctIH8ehd83QrVOmfggGoPeSCujWww99PHMTdjSTElwCpWfDhs248KQMKFrtwH7sEsi8E38A9NqNAl3astfzs7T1857UdzB0zhIdvn8swnUUisWYtVO2B/e9DeZEbPr4Pju+HYEtYQQPpIyFzjAvozDEwZMyp98EjXIu89giUvgN733avj0NPzEzJgrGfCAX8JTB0HAygm6rpXi7SpiUQ5Ju/LuZXH5Rx7YwR/OAzM9XnLbHhb4KDm12At77qK9y8pAwYNr59UGeOgSEFkJEH8efQADleBntbA/5PrtUPkD7qVOt97BK3/BjTzbnkjE6cbOFLT2/knV3H+NJl4/nK0sn9/p7d5yzQAnExvP+Kv+ncQsfL6o+50C5bB/s/gIObIBC6C+bQcTB6IYyeD/kLIWtyZLtFrIXK3S7Y977tWvINlafqMmax67bxxYOJc+++uNArPjTdd2rYF1amtXzudLcjOge6OZd068DxRu5+dD27K+r43qdncPO80bGuUt9rrofil2Hjky44xi6BOX8OF1wLCYOisP4G2L7SrX/fu6FgWOTCYcwi18IcQH/a90owCMd2nmp5l62Dqt1uXlyiO1C54F4YvcC90oZHt37GQNYE95r3BVffo9tOdc9s/437PgX9tOufPxvX/ggK7+7TaoNa6Oe9reU13P34ek42B/jp5+dy8UQP3d/aWtffuukJ+OglaK6DYRNg/OWw83fuz+xBmTDjZph9O4yY0ffrP7gJNj0JW1+EphoYMhYuvM61AMvWQGO1K5ueFwr4RVBwsatnpALe2ujvPIIB19L96EXY/io0VrnpKcNOBXf+Qhfm0djB9pVgEGzA/XxBv3vZ4KnhtumBULnQcPpI18o/B+pykU69UXyYLz+7maGpiTx61zwmeeWugvXHYMuzsOkpqNgOCSkw9VMutPMXujALBt2f1JuedAETaIIRM12Z6Z+B5MxzX39DFXz4vFv2kY8gfhBMucEte8ziU90FwSBU7IB977lX6XtQH3pqY2p2KOAvdu/Dp/SsmyEYdMuoKXevEwdOH26ohJFzYOIymHgl5M6MTBdGMAjlH7gQL37F1SsxDSZfDeMudd0ow8afP3+Z9BEFurRjreXR90r5t99uY8aoDH5xxzyyBw/wPt1gAHb/ATY+AR+/5s58GFUIc26HqTfCoPSuP9tQBVtXuO6QI1tdAF94vfvsmIt7HqR7/+iWseNVCDS71uac22HaTT3bQbT23e57D/atce81+928QZmQf5E7xW7kHGiqhROhoK45EArr/XDiUIezPoCEVMgY5Q7wZYxyBxXL1ri/HgBSh8OEK124j78cktvfF/6sWAuHNrsQ/+hlV8f4QTBpOUz7tNuJJCSf+/JFgS7uDonHG5qpqm/myXX7eGLtPpZPzeHHt8wmObGHZ7LUHYW3f+D6EHOmunAZs9gFV/y533e8V6r2wuanYfMzLtRShsGMW2H25yFnytktqzWMNj4JW18IdZEUuGXN+pz7M7mj4/vd+jc9DTWtXTi3uCDPnd77n+94mQv30nfde2tfcytfvKtXxuhTgZ0+yo23DicP6bwVXFcBu9+EXW+4nWFjtTuYlzffhfuEpZA7o2c7tKPbQyH+ojul0JcAE65wIT75akjyyF9//YAC3YOCQcuJky0cq3MhXVnXRGV9M5V1zVTVN3GsvpmqumYq65uorGumuqGZsKepce+ScTxw1QU9O5PlZA2s+Qms/R/wn3StrKrd7sAWuC6NvHmnDvDlFUa2FdbS6LpJNj3hDlJhXHjMvh0mX9M3O5eWRti20nWblL7jgm7ClW4d4y93IbjpSdj9FmBdF8Ls2yN/kLX2MBze6kI6I8+1rvuiuyQYgAMbYNdq97Md2uymp+W4n3vClTD+svat98rdUPySOz5xdJvbRmOXuBC/4FpIGdr7eslpFOgesbuijsfeK+WNbYeprGvGH+z8/y4jOYFhqYkMS0tkaGoiw9KSyEo9NZw/NIWZozPPvMKWRvjg5/DuD13rbeqn4LJvuKP/4Fp4ZWtc3+++Na6/GOvOVBg199RZHKPnn10L7Uz9wMd2QdMJyMx3ITrrs5E9P7hqj+uP3/xM6PxkA1h3IHP251zr/RxPQeu36o5CyZtQstq9nzzuTrkbPd/tsEvfPdVlk78Ipt3ojhNE+4yU85ACfQALBi1v76rg0fdK+dPOChLjfCydmkPBsBSGpiaR1RraoeEhqYm9v61swO+6Ef74Hag9COOvgCu+CSNndf+5xmp3ClprH/DBze7IvolzBxxbz+DIneHOcqhp7fc90IN+4BQX2umjXDfI1E9CwZLoXqYd8Luuib1/cq3VcZd56j4gXQr4Xeu9ZLVrwR/aAiNnu5b41E/2i4ttzicK9AGovsnPixvLeWxNKXsq6skenMTtC8dw2/z8yB3ADAZh+6/hD/8OlSWuG+WKf3WXQp+Lpjp3nvG+Ne51oMgdLOyotR84Pc/1+7YGd0beqeGu+oEl+vzNsTtmIrqwaCDZX9XA42tKea5oP7Un/czMy+DHt8zimukjSIyPUGvUWtfyfPP/uNZX9oVw6zOuP7o3IZqU5vq2J1zhxlsaXUvv6HZ3Dm7rgby04edHS9crFOb9lgK9H7DWsnZPJY++V8rvtx8hzhiunj6COxcVMCc/M7LP7iwvgt8/6A78ZebDp37mzsOORMAmJLsul4KL+37ZIqJAj6WTLQF+vfkAj75Xyo7DtQxJSeC+S8dz+8ICcjMifLXc0e2ua2XHq+4Oc1d/D+beqXuMiAxgCvQYOFxzkifXlfLM+2VUN7RwQe5gvvfpGVw/a2Rk727Y0uj6tLc85+4HnZjmzlpZ+Feue0REBjQFepQ9+0EZ33jlIwLWsvTCHO5aPJaF44ZGplvF3wwHN566qdD+991ByfhBcNGX4OK/17nCIh6iQI+i3310mK+/vJXFE7L4j09NZ/TQlL5dQTAAhz88FeD71kJLPWDcjacW/KW7aX/+Ql25J+JBCvQoeX9PJX/z7CZm5GXys9vnkpLYB5veWndzp9YAL33HXdUJkH2Bu+hl7BJ3cY9a4iKep0CPgu2HTnDPE0WMHpLMo3fO612YHy8LXdwSCvHWp7hkjnE3lBp7iTtvfHBu31ReRAYMBXqE7a9q4I5HPiA1MZ4nvrCAIalneQ6vv9ldXr9rNZT83rXIAdJy3ZWKY5e4AB9S0Od1F5GBRYEeQZV1TdzxyAecbAmw4ouLGJXZwxtWHd8fusz69+4y8+Y6d3+UMYvcvUsmXAnZk3XlpIi0o0CPkPomP3c/tp4Dxxt56p4FTM7t5iCkvxnK1p4K8YrtbnpGvnuazoSlriWuUwtFpBsK9AhoCQT5q6c3svVADT+7vZB5BZ0ckKwpP9WNsuePrhXuSwi1wj/nblGbNUmtcBHpMQV6HwsGLV974UPe3lnBdz89naVTctoX2LcWfvsVOFrsxjNGu0vtJ7a2wnU6oYicGwV6H/vP17bz8qYDfHX5ZG6Zl99+5qEt8MzN7qk6S//NtcLVFy4ifUSB3ocefns3P39nL3cuKuC+S8e3n1m5G576NCSlw52v6h7SItLnenQ/VmPMVcaYj40xJcaYB7ooc7MxZpsxptgY80zfVrP/e3FDOf+xagd/NmME37x2SvtL+U8cgic/6a7kvP1lhbmIRMQZW+jGmDjgIWApUA6sN8astNZuCyszEfgnYLG1ttoYc149h+qtHUf52osfsnjCMH5488z2z+lsrIanboT6SrjzN5A9KXYVFRFP60kLfT5QYq3dY61tBp4FbuhQ5i+Ah6y11QDW2qN9W83+a1NZNfc9vZELRwzmfz8/l6T4sLslNjfAM7e6p//c+rR7zqaISIT0JNBHAfvDxstD08JNAiYZY94zxqwzxlzVVxXsz0qO1nH3Y+sZnp7Eo3fOZ/CghFMzAy2w4g53h8Mbf+6eQSkiEkF9dVA0HpgIXArkAW8bY6Zba4+HFzLG3AvcC5Cf3+EMkAHmcM1J7njkA+J8hifunt/+OZ/BILxyH+x6A679sXuQrohIhPWkhX4AGB02nheaFq4cWGmtbbHW7gV24gK+HWvtw9baQmttYXZ29rnWOeZqGlq445EPqGls4bG75jNmWOqpmdbC61+Hrc/D5d+AwrtiV1EROa/0JNDXAxONMWONMYnArcDKDmVewbXOMcZk4bpg9vRdNWOv2R/kUE0jW8truOeJ9ew9Vs/Dt89l2qiM9gXf+QG8/1NYeB984h9iU1kROS+dscvFWus3xtwPvA7EAY9Ya4uNMd8Ciqy1K0PzlhljtgEB4KvW2spIVrwvNDYHOFbXREVdE8dqmzhW18yxuiYq69xwRV0Tx0LzTpz0t33OGPjJbbNZNCGr/QKLHnHP6ZxxCyz7ti4YEpGoMtbamKy4sLDQFhUVRX29a3ce5LGXV/Fe/Ujqmjv/2dMHxZM1OImstCSy0hJD76fGxw9PY3x2hxtlFb8MK+5yV3/e+jTEJXS6bBGR3jDGbLDWFnY277y7UvTo777PzxofoSYph5KCP+PIuBtJzp1MVloSw9ISGZaW2P7Uw57Y/Ra8+BcwegF85jGFuYjExHkV6A1NLUyv/B1HkseRkzeOubsfg7JHIG8+zLoNpt4I8T28Z3mrAxvg2c+5OyN+9jlI7OPnhIqI9FCPLv33io3v/4lx5iC1s+6Bz78If7cNln4Lmk7Aq38HP5jkuk12rYaA/8wLrNgJT90EqVlw+0uQnBnxn0FEpCvnVQu9adNztBBPwcW3uQnpI2Dxl2HR38DBTbDlV7B1BRS/BGk57uESMz8LOVNOX1hNubs/iy/e3Z9Fz/AUkRg7bwL9ZFMz06pWsytjIVPSOjxwwhgYNce9lv077Hzdhfu6n8Kan8CIWTDrczD9JkgZ6u7L8uSnoKkW7vwtDBvf6TpFRKLpvAn0rWteY56ppmr6Z7ovGJ8EU653r7oK12Lf8gy89lV3wdCk5a51frwMPv8SjJgRnR9AROQMzptA9295ngaSmPCJm3r+obRsuOg+9zr8kWu1f/gcNFTBLU9BweLIVVhE5CydF4He3HSSKcffYnvGJcwddI4PWs6dBrnfhisfhIZK9ZmLSL9zXpzlsuO9l8mgnriZZ+hu6Ym4BIW5iPRL50WgB7esoNoO5sLF18e6KiIiEeP5QG9pPMHkmncoHnI5SUmDYl0dEZGI8Xyg73lnBck0Ez/r5lhXRUQkojwf6HbrCg7aLGYtWh7rqoiIRJSnAz1QW8GE2vf5aOhSBiXqhlki4m2eDvSyd58hniBJc26JdVVERCLO04HuK36RXTaPwnkXx7oqIiIR59lAD1aXMaZuC8VDl5E6SN0tIuJ9ng30g+89BUDKXHW3iMj5wbOBHl/8EpuCE1lYODfWVRERiQpPBro9so3cxl1sy1pGurpbROQ84clAP7r2aQLWMHhuH9y7RURkgPBeoFtL0vaXWGOns2T21FjXRkQkajwX6LZ8PZlNB9metYzMlMRYV0dEJGo8F+hV7/+KJpvA0Lk3xroqIiJR5a1AD/gZ9PEr/CE4m8tmToh1bUREospbgV76NqktVWzPWs6wtKRY10ZEJKo89Qi6Ex/8Cmwyw+deF+uqiIhEnXda6C2NDCr5Lb8LzmfpjDGxro2ISNR5J9B3vUFioJ6Ps5aRk64nE4nI+cczXS71Rc/SYDMYNVsPshCR85M3Wugna0ja+3teDSxk+Yy8WNdGRCQmvBHo218l3jazLWs5ozKTY10bEZGY8ESXy8mNz3IkOJwJsy6JdVVERGJm4LfQa4+QuP9dfh1cxNXTR8a6NiIiMTPwA734ZXwE2TZsGfnDUmJdGxGRmBnwXS7Nm5+jJDiG6bMWxLoqIiIxNbBb6FV7SDy8kV8HFnHVtNxY10ZEJKZ6FOjGmKuMMR8bY0qMMQ90U+7TxhhrjCnsuyp246MXASgeeiXjs9OiskoRkf7qjIFujIkDHgKuBqYAtxljpnRSbjDwZeD9vq5kp6zFv/l5PghewNwZM6KyShGR/qwnLfT5QIm1do+1thl4Frihk3L/BnwXONmH9evakY+Ir9rJrwOLuGb6iKisUkSkP+tJoI8C9oeNl4emtTHGzAFGW2t/292CjDH3GmOKjDFFFRUVZ13ZdrauwE8cxZmXMSlH3S0iIr0+KGqM8QE/BL5yprLW2oettYXW2sLs7OxzX2kwSODDF3gnOJ3FMyZhjDn3ZYmIeERPAv0AMDpsPC80rdVgYBrwR2NMKbAQWBnRA6P71xFXe4BX/Iu4epq6W0REoGeBvh6YaIwZa4xJBG4FVrbOtNbWWGuzrLUF1toCYB1wvbW2KCI1Bti6giaTxPaMi5k6Mj1iqxERGUjOGOjWWj9wP/A6sB143lpbbIz5ljHm+khX8DSBFoLFr7A6MIfLpo9Td4uISEiPrhS11q4CVnWY9s0uyl7a+2p1Y/db+BqreNm/iL/W2S0iIm0G3qX/Jw5QEZ/LrsT5zMzLiHVtRET6jQF36X/ttM9z8ckfcuX0fHW3iIiEGXCB/ocdR2nyw9XTde8WEZFwAy7QE+J8LJ4wjLn5Q2JdFRGRfmXA9aFfM32ELvUXEenEgGuhi4hI5xToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiEQp0ERGPUKCLiHiEAl1ExCMU6CIiHqFAFxHxCAW6iIhHKNBFRDxCgS4i4hEKdBERj1Cgi4h4hAJdRMQjFOgiIh6hQBcR8QgFuoiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeIQCXUTEIxToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiEQp0ERGPUKCLiHhEjwLdGHOVMeZjY0yJMeaBTub/vTFmmzHmQ2PMm8aYMX1fVRER6c4ZA90YEwc8BFwNTAFuM8ZM6VBsE1BorZ0BvAB8r68rKiIi3etJC30+UGKt3WOtbQaeBW4IL2Ctfcta2xAaXQfk9W01RUTkTHoS6KOA/WHj5aFpXfkC8FpnM4wx9xpjiowxRRUVFT2vpYiInFGfHhQ1xnweKAS+39l8a+3D1tpCa21hdnZ2X65aROS8F9+DMgeA0WHjeaFp7RhjrgT+GbjEWtvUN9UTEZGe6kkLfT0w0Rgz1hiTCNwKrAwvYIyZDfwMuN5ae7TvqykiImdyxkC31vqB+4HXge3A89baYmPMt4wx14eKfR9IA1YYYzYbY1Z2sTgREYmQnnS5YK1dBazqMO2bYcNX9nG9RETkLOlKURERj1Cgi4h4hAJdRMQjFOgiIh6hQBcR8QgFuoiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeIQCXUTEIxToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiEQp0ERGPUKCLiHiEAl1ExCMU6CIiHqFAFxHxCAW6iIhHKNBFRDxCgS4i4hEKdBERj1Cgi4h4hAJdRMQjFOgiIh6hQBcR8QgFuoiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeER8rCtwtjYc2cCag2vISMwgIynslZhBelI6GYkZJMQlxLqaIiJRN+AC/aNjH/GLrb8gaINdlkmOT24L+dbAT09MbzecHJ9McnwyKQkpbcPJ8cmkxLvxQfGD8Bn9ASMiA4ex1sZkxYWFhbaoqOicPhu0Qepa6qhpquFE8wn33uTea5pr3HtouOP0lmBLj9cTHvRtYZ+QTHJcMvG+eOJ8ccT74ok38e499IozcafGTRfTO8yP88WR4Esg3oQtt5vP+4wPn/ERZ+Lav/vaj4uItxhjNlhrCzub16MWujHmKuC/gTjgF9ba73SYnwQ8AcwFKoFbrLWlval0d3zGR3piOumJ6Wf1OWstjf5GTjSfoNHf2O7V0NJwxmkNfjd+oukELcEWAjaAP+jHH/QTCAbwWz8twZZ24939JREN4YFvjGkb9xkfBoMxpu3dhw8MGEzn88Om+fDh8/nce9gOJPwVvs4zrbuz99YdUpfr77Cuztbf1bgxpt2y2/6FpgOnTTeY9tM7mxY+PbQtO64DQ1v9w3/W8J+x3XtYmdbp4ctu205d1MGH77T1t9a7N876/zH0/9bdtgyvX/jypWfOGOjGmDjgIWApUA6sN8astNZuCyv2BaDaWjvBGHMr8F3glkhUuDeMMaQkpJCSkBK1dQZtsC30/dbffgcQ9NNiW9qG/UE/ARs4tVMI22F0/GzABgjaYNt7+HAg2H5eeJnWcWstFtv23rrjCdpgu+nh81vHW4c7W3b4Olp3ep3NA7eDDRKk9a/EtvWE1tlVfbpbf+vP1roO8Y6udhatOwyf8bU1SjruGMMbLG3TwnYqrctvHQ/fkXRWrvX7Gf7dDf/edjkcKvflOV/muvHX9fk26kkLfT5QYq3dA2CMeRa4AQgP9BuAB0PDLwD/zxhjbKz6c/oRn/GRGJdIYlxirKty3ukY8OHB37aD6OQXEbr+BW033XLatHbTO3ym43Jbd06tO7XWnVT4zjW8ruE7so7rC19GZ3VoXWZ4XXqjq51+67YKr0/rz9KxfJfbuJtyp+38O+zkO+7ww7dju23KqW3QWeC2zQ/7Pw4v2zHw2/3V1GF6ZzuGnJScXv8fdKYngT4K2B82Xg4s6KqMtdZvjKkBhgHHwgsZY+4F7gXIz88/xyqL9Ex4603kfBDVb7u19mFrbaG1tjA7OzuaqxYR8byeBPoBYHTYeF5oWqdljDHxQAbu4KiIiERJTwJ9PTDRGDPWGJMI3Aqs7FBmJXBHaPgm4A/qPxcRia4z9qGH+sTvB17Hnbb4iLW22BjzLaDIWrsS+CXwpDGmBKjChb6IiERRj85Dt9auAlZ1mPbNsOGTwGf6tmoiInI2dAqAiIhHKNBFRDxCgS4i4hExuzmXMaYC2HeOH8+iw0VL/Yzq1zuqX+/19zqqfudujLW20wt5YhbovWGMKerqbmP9gerXO6pf7/X3Oqp+kaEuFxERj1Cgi4h4xEAN9IdjXYEzUP16R/Xrvf5eR9UvAgZkH7qIiJxuoLbQRUSkAwW6iIhH9OtAN8ZcZYz52BhTYox5oJP5ScaY50Lz3zfGFESxbqONMW8ZY7YZY4qNMV/upMylxpgaY8zm0OubnS0rgnUsNcZsDa37tCdyG+f/hrbfh8aYOVGs2+Sw7bLZGHPCGPO3HcpEffsZYx4xxhw1xnwUNm2oMWa1MWZX6H1IF5+9I1RmlzHmjs7KRKBu3zfG7Aj9/71sjMns4rPdfhciXMcHjTEHwv4fr+nis93+vkewfs+F1a3UGLO5i89GZRv2irW2X75wd3bcDYwDEoEtwJQOZe4D/jc0fCvwXBTrNwKYExoeDOzspH6XAq/GcBuWAlndzL8GeA0wwELg/Rj+Xx/GXTAR0+0HLAHmAB+FTfse8EBo+AHgu518biiwJ/Q+JDQ8JAp1WwbEh4a/21ndevJdiHAdHwT+oQffgW5/3yNVvw7z/wv4Ziy3YW9e/bmF3vYsU2ttM9D6LNNwNwCPh4ZfAK4wJjqPCLfWHrLWbgwN1wLbcY/iG0huAJ6wzjog0xgzIgb1uALYba091yuH+4y19m3cLaDDhX/PHgc+2clHlwOrrbVV1tpqYDVwVaTrZq19w1rrD42uwz2AJma62H490ZPf917rrn6h7LgZ+FVfrzda+nOgd/Ys046B2e5ZpkDrs0yjKtTVMxt4v5PZFxljthhjXjPGTI1uzbDAG8aYDaHnuXbUk20cDbfS9S9RLLdfqxxr7aHQ8GGgsyf89odteTfuL67OnOm7EGn3h7qFHumiy6o/bL9PAEestbu6mB/rbXhG/TnQBwRjTBrwIvC31toTHWZvxHUjzAR+ArwS5epdbK2dA1wNfMkYsyTK6z8j456CdT2wopPZsd5+p7Hub+9+d66vMeafAT/wdBdFYvld+CkwHpgFHMJ1a/RHt9F967zf/z7150Dv988yNcYk4ML8aWvtSx3nW2tPWGvrQsOrgARjTFa06metPRB6Pwq8jPuzNlxPtnGkXQ1stNYe6Tgj1tsvzJHWrqjQ+9FOysRsWxpj7gSuBT4X2uGcpgffhYix1h6x1gastUHg512sO6bfxVB+3Ag811WZWG7DnurPgd6vn2Ua6m/7JbDdWvvDLsrktvbpG2Pm47Z3VHY4xphUY8zg1mHcwbOPOhRbCfx56GyXhUBNWNdCtHTZKorl9usg/Ht2B/DrTsq8DiwzxgwJdSksC02LKGPMVcDXgOuttQ1dlOnJdyGSdQw/LvOpLtbdk9/3SLoS2GGtLe9sZqy3YY/F+qhsdy/cWRg7cUe//zk07Vu4Ly/AINyf6iXAB8C4KNbtYtyf3h8Cm0Ova4AvAl8MlbkfKMYdsV8HLIpi/caF1rslVIfW7RdePwM8FNq+W4HCKP//puICOiNsWky3H27ncghowfXjfgF3XOZNYBfwe2BoqGwh8Iuwz94d+i6WAHdFqW4luL7n1u9g61lfI4FV3X0Xorj9ngx9vz7EhfSIjnUMjZ/2+x6N+oWmP9b6vQsrG5Nt2JuXLv0XEfGI/tzlIiIiZ0GBLiLiEQp0ERGPUKCLiHiEAl1ExCMU6CIiHqFAFxHxiP8PBawFCMxlgYwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)\n",
    "plt.plot([i/100 for i in loss_history])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.258453, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.193012, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.359960, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.013943, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.188985, Train accuracy: 0.204889, val accuracy: 0.212000\n",
      "Loss: 2.567811, Train accuracy: 0.256667, val accuracy: 0.257000\n",
      "Loss: 2.310323, Train accuracy: 0.277778, val accuracy: 0.280000\n",
      "Loss: 2.762512, Train accuracy: 0.307444, val accuracy: 0.311000\n",
      "Loss: 2.996860, Train accuracy: 0.352667, val accuracy: 0.351000\n",
      "Loss: 3.422384, Train accuracy: 0.393667, val accuracy: 0.390000\n",
      "Loss: 3.660026, Train accuracy: 0.430778, val accuracy: 0.429000\n",
      "Loss: 4.075965, Train accuracy: 0.465111, val accuracy: 0.449000\n",
      "Loss: 4.114870, Train accuracy: 0.493000, val accuracy: 0.483000\n",
      "Loss: 4.729312, Train accuracy: 0.524889, val accuracy: 0.524000\n",
      "Loss: 5.280815, Train accuracy: 0.549778, val accuracy: 0.547000\n",
      "Loss: 5.491349, Train accuracy: 0.565667, val accuracy: 0.556000\n",
      "Loss: 5.789741, Train accuracy: 0.569556, val accuracy: 0.572000\n",
      "Loss: 6.104085, Train accuracy: 0.603000, val accuracy: 0.590000\n",
      "Loss: 6.456580, Train accuracy: 0.611111, val accuracy: 0.602000\n",
      "Loss: 6.451753, Train accuracy: 0.630000, val accuracy: 0.619000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5efe5b5410>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)\n",
    "plt.plot([i/100 for i in loss_history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.283436, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.158945, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.158044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.027027, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.023302, Train accuracy: 0.218667, val accuracy: 0.229000\n",
      "Loss: 1.788006, Train accuracy: 0.260000, val accuracy: 0.261000\n",
      "Loss: 1.949132, Train accuracy: 0.287000, val accuracy: 0.290000\n",
      "Loss: 1.393011, Train accuracy: 0.340222, val accuracy: 0.337000\n",
      "Loss: 1.716561, Train accuracy: 0.402111, val accuracy: 0.393000\n",
      "Loss: 1.812216, Train accuracy: 0.448889, val accuracy: 0.432000\n",
      "Loss: 1.714024, Train accuracy: 0.481778, val accuracy: 0.481000\n",
      "Loss: 1.403880, Train accuracy: 0.522111, val accuracy: 0.515000\n",
      "Loss: 1.491901, Train accuracy: 0.554222, val accuracy: 0.554000\n",
      "Loss: 1.324721, Train accuracy: 0.591222, val accuracy: 0.586000\n",
      "Loss: 1.388699, Train accuracy: 0.610111, val accuracy: 0.588000\n",
      "Loss: 1.330535, Train accuracy: 0.628000, val accuracy: 0.614000\n",
      "Loss: 1.396837, Train accuracy: 0.653333, val accuracy: 0.632000\n",
      "Loss: 1.170864, Train accuracy: 0.660556, val accuracy: 0.639000\n",
      "Loss: 1.111833, Train accuracy: 0.680556, val accuracy: 0.659000\n",
      "Loss: 0.710212, Train accuracy: 0.691556, val accuracy: 0.674000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5efe532910>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAo7klEQVR4nO3deXwU9f3H8ddncxFuAuEM4RYFFNGIgke1CqJWqPUCtWK1pVZp1da2Hv2pVVu19ahV2oqKlVqNeINyeGArVtSE+xIId8IVrgQIIcnu9/fHbHAJCVkgyW427+fjsY/dmfnuzCeb3ffMfmd2xpxziIhI/eeLdAEiIlIzFOgiIjFCgS4iEiMU6CIiMUKBLiISI+IjteA2bdq4rl27RmrxIiL10pw5c7Y551IrmxaxQO/atSvZ2dmRWryISL1kZuuqmqYuFxGRGKFAFxGJEQp0EZEYEVagm9kwM1tuZjlmdlcl058ys/nB2woz21XjlYqIyGFVu1PUzOKAccAQIBfIMrPJzrml5W2cc3eEtP85MKAWahURkcMIZwt9IJDjnFvtnCsBMoERh2k/CnitJooTEZHwhRPonYANIcO5wXGHMLMuQDdgZhXTx5hZtpll5+fnH2mtIiJyGDW9U3Qk8KZzzl/ZROfceOdchnMuIzW10uPiRURi0tbdxcz8ZgtPf7ySxXkFtbKMcH5YlAd0DhlOC46rzEjg1mMtSkSkPttaWMyivAIW5RWwOHi/pXA/AGaQ0jSRfp1a1Phywwn0LKCXmXXDC/KRwDUVG5nZ8UArYHaNVigiEsW2FBazKPfg8N66+9vw7pHalME92tCvUwtO7NSCPh2b0zSpdn6kX+1cnXNlZjYWmAHEAROcc0vM7EEg2zk3Odh0JJDpdAkkEYlR+8v8fLFqO/PX7zqwBZ4fDG9fMLzP6hkM77QW9OnQnCa1FN6VsUjlb0ZGhtO5XEQk2jnnmLNuJ+/My+P9hZso2FeKz6Bn26YHtrrLt7wbJ9Z+eJvZHOdcRmXTInZyLhGRaLZm217emZfHu/PyWL+jiEYJPi7s257vD+jE6d1Sji68d66FVZ9C17OhTc8ar1mBLiIStHNvCe8v3Mjb8/KYt34XZjC4R2t+cX4vhvVrf+R938UFsGYWrP4UVs2EHau98UP/AG3G1nj9CnQRadCKS/3M/GYr78zL4z/Lt1Lqdxzfvhl3X3Q8w0/uSIcWyeHPzF8GG+d64b3qU8jNAueHhCbQ9SwY+FPo8V1o06tW/hYFuog0OIGAI3vdTt6Zl8sHCzdRWFxG22ZJ3DC4K5cNSKNPx+bhz2zHai+8V830tsb3FwAGHQfAWbd7AZ42EOITa+vPOUCBLiIxLRBwbN29n/U7itiwo4gVW3fzwcJN5O7cR+PEOIYF+8XP7NmGOJ9VP8N9u2DNZ992o+xc641v0Rn6jvACvNt3oHFKbf5ZlVKgi0i9V1hcyvrtReTuLAoG9z7vfmcRuTv3UVIWONDWZ3Bmzzb8auhxDO3TPrzDCkuLYcU0WPA65HwEgTJIbArdzoEzbvVCvHUP78DzCFKgi0i9sWd/GVMXbWJV/h42hAR3wb7Sg9q1SE6gc0oyx7dvxpAT2tE5pTGdUxqTntKYji0bkRQfV/3CAgFY/wUsfB2WvOd1pTTrAGf8DHpfAmkZEJdQS3/p0VGgi0jU21pYzEtfrOWVL9exu7iMxDgfaa2SSUtpTP/OLUhPaUznVo0PBHeL5GMI2vwVsDATFr4BBeu9HZp9hsNJV3tb5L4wVgYRokAXkaiVs3UPz3+2mnfm5VEaCHBRv/b8+OzunJzWEl84/d3h2pMPi9+EBZmwaT6Yz+tGOf//4PhLILFJzS2rFinQRSTqZK/dwT/+u5qPl20hKd7HVael8eOzutO1TQ0Ga0kRLJ/qdankfOIdXtj+JLjwj9DvCmjWruaWVUcU6CISFQIBx0fLtjD+s9XMWbeTlo0T+MX5vbh+UBfaNE2qgQX4oXAj5C+HJW/D0slQshuad4LBP4f+I6HtCce+nAhSoItIRBWX+nl3Xh7jZ61mdf5e0lol88ClfbjqtM5H9vP6QAD2bIFd62DXeti5Lvg4OFyQ6x2dApDYDPqMgP5XQ5ezwFfTl4aIDAW6iEREQVEpr3y1jpf+t5Zte/bTr1Nznhk1gIv6tSc+roqADQRg80LYsSoY2Ou/DexdG8C//+D2TdpCy3TodCr0vQxadoFWXaDzGZDYuPb/yDqmQBeROpW3ax8TPl9D5tfr2Vvi55zjUrn5nO4M6tEaq+w47oAf1s+Gpe/Bsimwe9O305JTvIBu1xd6X+yFd6uu3n2LzjEZ2oejQBeRWre5oJgZSzYzbfEmvl6zA58Zl/bvyE/O7l75z+z9pbB2ltfP/c37sDcf4htBzwvghEuh/YleaCc1q/s/Joop0EWkVmzYUcT0xV6Iz12/C4BebZsy9ryeXD0wnU4tK5z0qmw/rP6vtyW+/APYt9M7Bvy4oV5/d88hkNS07v+QekSBLiI1JmfrngNb4ovzCgHo27E5dw49jmH9OtCzbYVALt3nHTK4bDIsnwb7CyGpOfS+CE4YDj3Ph4QjONthA6dAF5Gj5pxj2abdTF+8iWmLN7Ny6x4ABqS35J6Lj2dY3w6kt67Qj71/j3c+lKXvwYoPoXQvJLfyArzPCOj+HYivgcMUGyAFuogcEeccC3ILmLZ4EzMWb2bt9iJ8BgO7pXDt6X24sF/7ys8hvmsDzH4W5k6E0iJokgonXeX9rL7r2VF3XpT6SIEuItVyzrEor4ApCzYyddFm8nbtI95nDOrRmjHn9GBo33ZV//gnfzl8/hdYNMkbPvFKGHAdpA+K6vOi1EdhBbqZDQOeBuKAF5xzj1bS5irgAcABC5xz19RgnSJSx5xzLN+ymykLNvL+wk2s215EQpxxTq9U7hhyHENOaEeLxofZqs6dA58/6R2lEp8Mp/0YBo2Flp3r7o9oYKoNdDOLA8YBQ4BcIMvMJjvnloa06QXcDZzpnNtpZm1rq2ARqV2r8vfw/oJNTFm4kZyte4jzGYN7tObWc3tyYd/2hw9x57wLP3z+lHcRiEYt4JzfwOk/hSZt6u6PaKDC2UIfCOQ451YDmFkmMAJYGtLmJ8A459xOAOfc1pouVERqz4YdRby/cBNTFmxk6aZCzGBg1xRGf78fF/VrX/25VAJ+b0t81pPe2QqbtoehD8OpN+hY8ToUTqB3AjaEDOcCp1docxyAmf0Pr1vmAefc9IozMrMxwBiA9PT0o6lXRGrI5oJiPljkhfj8DbsA7+iU//teHy45sQPtWzSqfiZlJd7ZCv/3NGxfCSnd4dK/eie60pEqda6mdorGA72Ac4E04DMzO9E5tyu0kXNuPDAeICMjw9XQskUkTCVlAd6Ys4H35m8ka+0OnPOOE7/rouO55MQOdE4J86fy+/fA3Jfhi2dh90bvtLNXvOQddqgdnRETTqDnAaF7MdKC40LlAl8550qBNWa2Ai/gs2qkShE5Zks2FnDnGwtZtqmQnm2bcscFx/G9kzrQvXWy9wOfsiLYtc27fmbZPu++tAjKioPTg8O7Nnhhvm+nd7jhiGegx/kRv56mhBfoWUAvM+uGF+QjgYpHsLwLjAJeMrM2eF0wq2uwThE5SqX+AOM+zWHczBX8MPkL3mj7IU0ChdjXxfC/IgiUVj+TinpfDGf9EjqfVvMFy1GrNtCdc2VmNhaYgdc/PsE5t8TMHgSynXOTg9OGmtlSwA/82jm3vTYLF5HqLdtUyJ1vLCBpUzaftHiV9OIV0HQAtB/s/aQ+Idk7pDChUfC+fFyjKh4ne5dj0zlVopI5F5mu7IyMDJednR2RZYvEujJ/gH/8dxWZn3zFPYmZXOxmeVesH/Kg98MedY/UW2Y2xzmXUdk0/VJUJMYs37ybuydlMWjLa3ySOJlEn4PBd8JZd2jLOsYp0EViRJk/wHP/XcWyma/yTPwrdErYCsdfCkMegpRukS5P6oACXSQGrNyym2dee4+rt/+NW+OXUNbmBLj4Be/MhdJgKNBF6jF/wDFx5lwSP3uUp3wf4W/UHIY8TvypP4I4fbwbGv3HReqpnM27mPnKo1y1eyLNfPsoOflGkof+DhqnRLo0iRAFukg94w84pk/OpNe8hxljueSnno7vyqdIbtc30qVJhCnQReqRlTkr2P7GbVyy/wvyEzqw6+KXSB1wmQ5DFECBLlIv7NxbwvQ3xjNszSOkWQlLTriNPj+4G9P1NiWEAl0kipX5A0z64huSP7mHUXxKXuPexF3zT/p27hPp0iQKKdBFotQXOdvIfOcdfrn7z6T7trJ9wFg6XXI/xCdGujSJUgp0kSizYUcRj7y/mJ7Ln+PJhLcpbdoeu+p9Wnc9K9KlSZRToItEiaKSMv7+n1VM/Ww2f44bxykJK/D3vYLk7z0ByS0jXZ7UAwp0kQhzzjF5wUYenbqMwXs+4oNGE0mMj4PvvUDcSVdGujypRxToIhG0OK+A309Zwoq1G3i2+UTOTvwc0gbDD56DlrpMoxwZBbpIBGzfs5/HP1xOZtYGhiYvZ3bLv5NcsgPOvw/OvF2XcZOjokAXqUP+gOPlL9by1Mcr8JcU82r6NAZteQ2a9IQfvg6dTol0iVKPKdBF6simgn3cljmfr9fsYFTXvTxQ+hRJW5ZCxo0w9GHvSkAix0CBLlIHPlq6hV+/uYDSsjLezVhM/2+exBKbwqhM6H1RpMuTGKFAF6lFxaV+Hpm6jJdnr+OSdjt4ovHLNFqcBT2HwIhx0KxdpEuUGKJAF6klOVv38PPX5rF201b+3WUmg/MzsZLmMPxZGHCdTqglNc4XTiMzG2Zmy80sx8zuqmT6DWaWb2bzg7cf13ypIvWDc45J2Ru49JnP6V0wi3kpv+PMLa9g/UfC2Gw45YcKc6kV1W6hm1kcMA4YAuQCWWY22Tm3tELT151zY2uhRpF6Y3dxKfe+s5jsBQuZ2PI1TiueDU1OgKsnQJdBkS5PYlw4XS4DgRzn3GoAM8sERgAVA12kQZu/YRd3vJrFhbvf5r+N3ybe74MLfg+DboW4hEiXJw1AOIHeCdgQMpwLnF5Ju8vN7BxgBXCHc25DxQZmNgYYA5Cerl/BSWwIBBzPz1rNJx9O5oXECfSIXw89L4KL/6Rfe0qdCqsPPQxTgK7OuZOAj4CXK2vknBvvnMtwzmWkpqbW0KJFIid/937GvvgJzT/6FZMSHqBbUz+MfBWuyVSYS50LZws9D+gcMpwWHHeAc257yOALwJ+OvTSR6PbZ8q3MfP0vPOyfSMuEItygX+D7zm8hqWmkS5MGKpxAzwJ6mVk3vCAfCVwT2sDMOjjnNgUHhwPLarRKkShS6g/w0rvT6b/g9zzg+4Z97TPwXfY0tO8X6dKkgas20J1zZWY2FpgBxAETnHNLzOxBINs5Nxn4hZkNB8qAHcANtVizSMSs2Lidhf+6ix8VvUVpQhNKLnya5IzrwVdTvZciR8+ccxFZcEZGhsvOzo7IskWO1O7iUv4+fR5nzb2dwb4lbEi/jM5XPw5N2kS6NGlgzGyOcy6jsmn6pajIYTjneHd+Hs9/8D+eKHmY43x57Ll4HJ0HXhfp0kQOoUAXqcLSjYXcP3kxu9Yt4tXkP5OStI+4kW/StMd3I12aSKUU6CIVFOwr5amPVjBx9lrOa7SSfzd5nIRGjbFrp0GHkyJdnkiVFOgiQYGA4825uTw27Rt2FpXwx96ruHrDH7CWXeHaN6FVl0iXKHJYCnQRYFFuAfdNXsy89bs4Jb0l75+2kA5fPgSdT4dRr0HjlEiXKFItBbo0aDv3lvD4h8t59ev1tG6SyONXnMjl257DvnwWjv8eXP4CJCRHukyRsCjQpUHyBxyvZ23gTzO+YXdxGTcM7sod53Wh+fRfwOK3YOAYGPaoLtYs9YoCXRqceet3cv/kJSzMLWBgtxQeHNGX41sE4PWRsHaWd4bEM2/TOcul3lGgS4PhnONv/1nF4x8uJ7VpEk+PPJnh/TtihRvhpStg20r4wfNw0lWRLlXkqCjQpUHYX+bnnrcX89bcXEac3JE/XHYiTZPiYctS+PcVUFwI170J3c+NdKkiR02BLjFvx94Sbv7XHL5eu4M7LjiOX5zfEzODNbMg81pvp+eN06D9iZEuVeSYKNAlpq3K38ON/8xiU0Exfx01gOH9O3oTFr8F79wMrbp5W+Y6d7nEAAW6xKwvcrZx8ytzSIjz8dpPzuDULq2CE56FD++F9EHexSh0jLnECAW6xKTMr9fzu3cX0z21CS+OPo3OKY1h3y6YeicsegNOGO7tAE1oFOlSRWqMAl1iij/geGz6N4z/bDXnHJfKs9cMoHmjBFj7P3jnp1C4Ec67F87+lY4xl5ijQJeYUVRSxm2Z8/lo6RauH9SF+77Xh3hXBh8/AJ//BVK6wU0fQlqlp5IWqfcU6BITNhcUc9PLWSzbVMgDl/bhhjO7Qf4KePvHsGkBDPih98tPXe9TYpgCXeq9xXkF3PRyFnuKy3hx9Gmc1zsVsl6EGfd6hyRe/QqccGmkyxSpdQp0qddmLNnM7ZnzSWmSyFu3DOb4pvvhtVGwYhr0+C6M+Bs07xDpMkXqhAJd6iXnHOM/W82j07/hpLSWPH/9qbTd9Bn86xbvV5/DHoWBP9XFm6VBCevdbmbDzGy5meWY2V2HaXe5mTkz014nqTUlZQHuemsRj0z7hotP7MDrPzqJtp/9Dl69Epq0hTGfwhk/U5hLg1PtFrqZxQHjgCFALpBlZpOdc0srtGsG3AZ8VRuFigAUFpfy04lzmL16Oz//bk/u6LsP34TzYdtyOONWOP8+HVsuDVY4mzADgRzn3GrnXAmQCYyopN1DwGNAcQ3WJ3LA/jI/P504h6y1O3jiihP5VeNp+F68APYXwg/fhWF/VJhLgxZOoHcCNoQM5wbHHWBmpwCdnXMfHG5GZjbGzLLNLDs/P/+Ii5WGKxBw3PnGQmav3s4zl6Ry+eJb4OP7ofcw+NkX0OO8SJcoEnHHvFPUzHzAk8AN1bV1zo0HxgNkZGS4Y122NByPTFvGlAUb+csZe7lo1uUQ8MOIcXDytboQhUhQOIGeB3QOGU4LjivXDOgH/Me8D1Z7YLKZDXfOZddUodJwvTBrNc/PWsN9JxUwYsmd0CINrsmElO6RLk0kqoQT6FlALzPrhhfkI4Fryic65wqANuXDZvYf4E6FudSEKQs28vAHy7i1xzZ+tPYerHlHGD0FmrWLdGkiUafaPnTnXBkwFpgBLAMmOeeWmNmDZja8tguUhuuLVdv41aQFXNNxK3fm34M1bacwFzmMsPrQnXNTgakVxt1XRdtzj70saei+2VzITyfOYUjLPP6w5wGsSSrc8L5+9SlyGPqlqESdvF37GD3ha05JWMczZQ9jjVOCYd4x0qWJRDX9lE6iSkFRKTdM+JrO+1cxIe5hfI1aeGHeIi3SpYlEPQW6RI3iUj8/mZhNo+3LeK3RI8QlNYMbpuh6nyJhUpeLRAV/wHHH6/PZtW4BU5o9SkJishfmrbpGujSRekOBLhHnnOPBKUtYsWQO7zd7jKSkRl43i44zFzkiCnSJuOc+W82sL2czuemjJCcmeIcmtu4R6bJE6h0FukTU23NzyZz+Ke81foQmiT4vzNv0inRZIvWSdopKxMxamc+zb37EW8mP0DwJbPQUSO0d6bJE6i1toUtELM4r4KF/TSMz6WFaJQWw66dA2xMiXZZIvaZAlzq3YUcR97z0AS/7HqRNkh/f9ZOhfb9IlyVS7ynQpU5t37OfX7/wAX8ru5+2SSVemHc4KdJlicQEBbrUma2FxdwxfgqP7b2X9on7iLt+MnQ8OdJlicQMBbrUiY279vHQPyby9L4/0DIxQPzod6HTKZEuSySmKNCl1q3fXsT4557kqf1/wZq1J370WzqaRaQWKNClVq3aupsZz/2Wh/3/Zm+7U2kyehI0aVP9E0XkiCnQpdYsz9vO8hdu4hb3KQU9v0+Lq5+DhEaRLkskZinQpVYsW7WOvf8ayXCWsiPjl6Rccp8u5ixSyxToUuOWLppL8lvX0IN8tg19ljaDfxjpkkQaBAW61Kils6fRcfqPwYxdV7xJ237nRbokkQZD53KRGrN8xvP0nH4thXEtKLvxY4W5SB0LK9DNbJiZLTezHDO7q5LpN5vZIjObb2afm1mfmi9VolYgwJpJd9N79p0sTehLk1s+pU368ZGuSqTBqTbQzSwOGAdcBPQBRlUS2K865050zp0M/Al4sqYLlShVWsymCdfSbenf+DBpKF1vm0brNu0iXZVIgxTOFvpAIMc5t9o5VwJkAiNCGzjnCkMGmwCu5kqUqLUnnx1/v5AOuVOZ2PRGzrj937Rs1jTSVYk0WOHsFO0EbAgZzgVOr9jIzG4FfgkkAt+tbEZmNgYYA5Cergv/1mtbv2HPSz8guSifJ1J+x80330GTJO1jF4mkGtsp6pwb55zrAfwW+F0VbcY75zKccxmpqak1tWipa6tmUjL+fIqK9vJIuye45We/VJiLRIFwPoV5QOeQ4bTguKpkAn8/lqIkSu3dBrOeIPDVc6zyd+SlLo/x0OhhJMXHRboyESG8QM8CeplZN7wgHwlcE9rAzHo551YGBy8BViKxo7gAvngW/xfjsLJ9TCo7h6zj7uTRa88kIU5HvopEi2oD3TlXZmZjgRlAHDDBObfEzB4Esp1zk4GxZnYBUArsBEbXZtFSR0r3wdfjKfvsSeL372Ka/3RejB/FBeefzWPndCdeYS4SVcLq+HTOTQWmVhh3X8jj22q4Lokkfylu7kRKZj5G0r4tfO7vzwuJd3P2eUN45Ywu6i8XiVL6ZMq3AgHcojco/ughkvdsYFHgOJ5PvJXTLxjO8wPTSU5UX7lINFOgCziHWz6VPdN+T7OC5awJdGFC4j30/+5VPH1aOo0SFOQi9YECvYELrP6Mgvf/j1Y75rMt0I4nGv2S488fzR9PTScxXn3kIvWJAr2B8ufOZft799I2/wuKXQpPNLqVrhf8hHtP6aIjV0TqKQV6A+PPz2HzW7+l0+aPiXdN+UejG+k0dCy3D+hOnE8XoBCpzxToDUVxIXs/fpSk7Odo4eJ5JXkUbYf+ijEn98SnIBeJCQr0WBcIwIJXKZlxP02Kt/FW4Fzih9zPtWcNwHRJOJGYokCPZeu/wk37DbZpPosDPXmx2d3cdv3VHNeuWaQrE5FaoECPRQV58PEDsGgSO32tebDkFuL6X82fL+tH40T9y0VilT7dsaS0GGY/A7OeJOAv4yW7nHGll3L3DzK4MqNz9c8XkXpNgR4LnINlU+DDe2HXela2Po+bNg4nKbUHmdeeoi4WkQZCgV7fbVkC034La2dR1vp4Hm39CC/kdeGKU9N4cERfdbGINCD6tNdXRTvg0z9A9gRIak5Oxv1cO68PhSXw+JX9uOLUtEhXKCJ1TIFe35SVwJx/emG+v5BAxk38gyv58+fb6JmazCtjTqGXulhEGiQFen1RkOsF+ZyXYe9W6HYO28/6Pbd8vJ+v1mzjylPT+L26WEQaNH36o5lzsOa/8PXzsHwauAD0GgoDxzDLncTtry6gqMTPE1f253J1sYg0eAr0aFRcAPNfg6wXYPtKSE6BwWMh40ZKmqXz7MyVPPNpFr3aNiXzGnWxiIhHgR5NtizxtsYXToLSvdDpVPj+P6DvZawp8JM5ez1vzvmE7XtLuCojjd8P76eLTojIAQr0SCsrgWWTva3x9bMhvhH0uwJOu4n97frz4ZItvPrSfGav3k6cz7jghLZcd0YXzu6VGunKRSTKKNAjpSAP5rz07U7OVl1hyEMw4DpW700kM2sDb86ZyY69JaS1SubXF/bmylPTaNu8UaQrF5EoFVagm9kw4GkgDnjBOfdohem/BH4MlAH5wI3OuXU1XKtnzSxYMb1WZl1ndq6tsJPzJ+zvei7Tl2zltVeW8+XqHcT7jCF92jFqYDpn9WyjU9yKSLWqDXQziwPGAUOAXCDLzCY755aGNJsHZDjniszsZ8CfgKtro2A2L4Lsl2pl1nUmqdmBnZw5pW3I/Ho9b732KTuLSklPacxvhvXmilPTaNtMW+MiEr5wttAHAjnOudUAZpYJjAAOBLpz7tOQ9l8C19VkkQcZdIt3q8eKS/1MX7yZVyet5+s1S4j3GRf2bc+ogekM7tFaW+MiclTCCfROwIaQ4Vzg9MO0vwmYVtkEMxsDjAFIT08Ps8SDTcrawPhZq4/qudFia2ExhcVldGndmLsuOp7LT0kjtVlSpMsSkXquRneKmtl1QAbwncqmO+fGA+MBMjIy3NEso1WTRHrX8+OuT01vxfCTOzKou7bGRaTmhBPoeUDoybTTguMOYmYXAPcC33HO7a+Z8g41pE87hvRpV1uzFxGpt3xhtMkCeplZNzNLBEYCk0MbmNkA4DlguHNua82XKSIi1ak20J1zZcBYYAawDJjknFtiZg+a2fBgsz8DTYE3zGy+mU2uYnYiIlJLwupDd85NBaZWGHdfyOMLarguERE5QuF0uYiISD2gQBcRiREKdBGRGKFAFxGJEQp0EZEYoUAXEYkRCnQRkRihQBcRiREKdBGRGKFAFxGJEQp0EZEYoUAXEYkRCnQRkRihQBcRiREKdBGRGKFAFxGJEQp0EZEYoUAXEYkRCnQRkRihQBcRiRFhBbqZDTOz5WaWY2Z3VTL9HDOba2ZlZnZFzZcpIiLVqTbQzSwOGAdcBPQBRplZnwrN1gM3AK/WdIEiIhKe+DDaDARynHOrAcwsExgBLC1v4JxbG5wWqIUaRUQkDOF0uXQCNoQM5wbHHTEzG2Nm2WaWnZ+ffzSzEBGRKtTpTlHn3HjnXIZzLiM1NbUuFy0iEvPCCfQ8oHPIcFpwnIiIRJFwAj0L6GVm3cwsERgJTK7dskRE5EhVG+jOuTJgLDADWAZMcs4tMbMHzWw4gJmdZma5wJXAc2a2pDaLFhGRQ4VzlAvOuanA1Arj7gt5nIXXFSMiIhGiX4qKiMQIBbqISIxQoIuIxAgFuohIjFCgi4jECAW6iEiMUKCLiMQIBbqISIxQoIuIxAgFuohIjFCgi4jECAW6iEiMUKCLiMQIBbqISIxQoIuIxIiwzoceTdYVrmPVrlUYhpnhM2+d5DPfgXEHpuE7eDjYBsDMDppv+fgqhytrb9+2C112aHvDKp3mM9+B+nzmO+hmhDeu/G8XEYF6GOifrP+Ep+Y8FekyokZ5sMdZ3LdBjw+fzxtnmDfNFxwfsjIoH1/+3Kruy597YLwvjniLJ97n3SoOHxhvccT74knwJRx4HHpL8CUcuB0YjqswHDo9ZFq8xR+ykhVp6OpdoA/vMZxBHQYRIAAOHI6AC+BwOOe+HQ4+PmhcyHAo5yoMV5heUei8y9s7r5hvH4e2C04rbxtaS8AFvr0RODDO7/wHHpc/p3zcgWkE8Af8B54bCATb4PAHgvfOf9Ay/M5PIBBs7759fnm70PuSQMmh7Z0ff8CP3/kpC5QduB007Lz72lYe+hXvKxsXuhKpuNIJHXfIiscOXUmVt4+zuAMrszhf3EHDoSu6itPKh0PnEWcHt9HKSo5GvQv0NsltaJPcJtJlSDXKVzwVgz808Ev9pZQGSr3HgdJvb/5Syty308tv5e1K/CUHzS90Wuh9xXHFZcUHzeuQFVFIbWWBsmpX7LWp/FtUxRVA+Ten0Mfl37TiLf7AN6jyb1MVx5WvNCp+szvk3nfw80PHhX4bPOibYYX5mFmVwwfdgl2P5W0qTvNZhekh4yrruizvnqxuemg3bejj+qzeBbrUD2bmbakST1JcUqTLOSqh30TKVwLlw/6AnzJX9m2b4OOD2gS/zRzULriyKP+2U94u4AIHPad8ZVj+/KqmBwKBA9MPel6wXWnAWzmWf3sLfX5l38xCv8WFzqt8WkMQuhKouHKouAKoah9e6D6uytr+rP/PGNZtWI3XHlagm9kw4GkgDnjBOfdohelJwETgVGA7cLVzbm3NlipSt+J8ccQRR2JcYqRLiQoHdRFycHdd+TeyIxkO7WYsn1belRjazXdIN6Pzg+OQbsrQ7smD5uUCB3Vfls8rtHs2dD4HdYcGu3YrLqv8ucBhu3wPaus4MI/mic1r5X9UbaCbWRwwDhgC5AJZZjbZObc0pNlNwE7nXE8zGwk8BlxdGwWLSGSUd3vEEeeNiItsPXKocI57GwjkOOdWO+dKgExgRIU2I4CXg4/fBM63+t4ZJSJSz4QT6J2ADSHDucFxlbZxzpUBBUDrijMyszFmlm1m2fn5+UdXsYiIVKpOf5ninBvvnMtwzmWkpqbW5aJFRGJeOIGeB3QOGU4Ljqu0jZnFAy3wdo6KiEgdCSfQs4BeZtbNzBKBkcDkCm0mA6ODj68AZrqKv9YREZFaVe1RLs65MjMbC8zA2689wTm3xMweBLKdc5OBF4F/mVkOsAMv9EVEpA6FdRy6c24qMLXCuPtCHhcDV9ZsaSIiciR0uj4RkRhhkerqNrN8YN1RPr0NsK0Gy6lpqu/YqL5jF+01qr6j18U5V+lhghEL9GNhZtnOuYxI11EV1XdsVN+xi/YaVV/tUJeLiEiMUKCLiMSI+hro4yNdQDVU37FRfccu2mtUfbWgXvahi4jIoerrFrqIiFSgQBcRiRFRHehmNszMlptZjpndVcn0JDN7PTj9KzPrWoe1dTazT81sqZktMbPbKmlzrpkVmNn84O2+yuZVizWuNbNFwWVnVzLdzOyvwddvoZmdUoe19Q55XeabWaGZ3V6hTZ2/fmY2wcy2mtnikHEpZvaRma0M3req4rmjg21WmtnoytrUQm1/NrNvgv+/d8ysZRXPPex7oZZrfMDM8kL+jxdX8dzDft5rsb7XQ2pba2bzq3hunbyGx8Q5F5U3vPPGrAK6A4nAAqBPhTa3AP8IPh4JvF6H9XUATgk+bgasqKS+c4H3I/gargXaHGb6xcA0wIAzgK8i+L/ejPeDiYi+fsA5wCnA4pBxfwLuCj6+C3iskuelAKuD962Cj1vVQW1Dgfjg48cqqy2c90It1/gAcGcY74HDft5rq74K058A7ovka3gst2jeQo/qKyU55zY55+YGH+8GlnHohT+i3QhgovN8CbQ0sw4RqON8YJVz7mh/OVxjnHOf4Z1gLlTo++xl4PuVPPVC4CPn3A7n3E7gI6BGrwJcWW3OuQ+dd1EZgC/xTm8dMVW8fuEI5/N+zA5XXzA7rgJeq+nl1pVoDvQau1JSbQt29QwAvqpk8iAzW2Bm08ysb91WhgM+NLM5ZjamkunhvMZ1YSRVf4gi+fqVa+ec2xR8vBloV0mbaHgtb8T7xlWZ6t4LtW1ssFtoQhVdVtHw+p0NbHHOraxieqRfw2pFc6DXC2bWFHgLuN05V1hh8ly8boT+wDPAu3Vc3lnOuVOAi4BbzeycOl5+tcw7x/5w4I1KJkf69TuE8757R92xvmZ2L1AG/LuKJpF8L/wd6AGcDGzC69aIRqM4/NZ51H+eojnQo/5KSWaWgBfm/3bOvV1xunOu0Dm3J/h4KpBgZm3qqj7nXF7wfivwDt7X2lDhvMa17SJgrnNuS8UJkX79Qmwp74oK3m+tpE3EXkszuwH4HnBtcIVziDDeC7XGObfFOed3zgWA56tYdkTfi8H8+AHwelVtIvkahiuaAz2qr5QU7G97EVjmnHuyijbty/v0zWwg3utdJyscM2tiZs3KH+PtPFtcodlk4Prg0S5nAAUhXQt1pcqtoki+fhWEvs9GA+9V0mYGMNTMWgW7FIYGx9UqMxsG/AYY7pwrqqJNOO+F2qwxdL/MZVUsO5zPe226APjGOZdb2cRIv4Zhi/Re2cPd8I7CWIG39/ve4LgH8d68AI3wvqrnAF8D3euwtrPwvnovBOYHbxcDNwM3B9uMBZbg7bH/Ehhch/V1Dy53QbCG8tcvtD4DxgVf30VARh3/f5vgBXSLkHERff3wVi6bgFK8ftyb8PbLfAKsBD4GUoJtM4AXQp57Y/C9mAP8qI5qy8Hrey5/D5Yf9dURmHq490Idvn7/Cr6/FuKFdIeKNQaHD/m810V9wfH/LH/fhbSNyGt4LDf99F9EJEZEc5eLiIgcAQW6iEiMUKCLiMQIBbqISIxQoIuIxAgFuohIjFCgi4jEiP8HjLGxENvvk4AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 0)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)\n",
    "plt.plot([i/100 for i in loss_history])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.308775, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.301469, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.284900, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.284201, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.296964, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.274332, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.249938, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.268191, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.303653, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.239989, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.254519, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.198031, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.155267, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.177020, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.163194, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.152747, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.991861, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.773205, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.243088, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.096283, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.336770, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.687034, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.955257, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.037137, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.878304, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.671916, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.062169, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.370697, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.654658, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.235574, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.555130, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.197309, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.300577, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.383807, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.473779, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.797975, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.338295, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 0.665117, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.313578, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.136341, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 0.620989, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.561076, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.016724, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.113275, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.407916, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.099731, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.138305, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.102920, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 0.965028, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.581668, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 0.883443, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.026181, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 0.717551, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.916547, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.733198, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.280679, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.976753, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.859488, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.708322, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.717690, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.762699, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.248053, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.754982, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.312727, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.326004, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.780309, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.979399, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.616719, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.380962, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.892620, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.211443, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.478319, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.101969, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.893688, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.774650, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.541063, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.116564, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.850573, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.075670, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.327845, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.584872, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.300217, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.453339, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.657614, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.102660, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.513168, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.494555, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.414858, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.077215, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.355038, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.280799, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.052163, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.310138, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.073137, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.390629, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.343411, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.075796, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.386339, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.211119, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.195703, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.150400, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.190225, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.044076, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.088469, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.130505, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.041371, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.077077, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.159724, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.083738, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.037626, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.076451, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.127641, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.032770, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.056717, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.057668, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.049450, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.125849, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.027837, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.114464, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.121435, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.032018, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.037581, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.061867, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.022928, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.096016, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.080560, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.067572, Train accuracy: 1.000000, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.084197, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.049357, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.036001, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.095927, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.070101, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.033661, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.061697, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.075557, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.029033, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.017244, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.058827, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.048383, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.021510, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.058999, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.022210, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.035695, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.040946, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.027055, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.017200, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.027419, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.036578, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.012713, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.018340, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 0)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-2, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.332987, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.362128, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.551714, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5.949216, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 3.963839, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 6.334563, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 33.250267, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 115.200660, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.000000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.000000, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marie/DL_/assignment2/layers.py:60: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.mean(-np.log(probs[rows, cols]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.333333\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.333333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.000000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.000000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.333333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.400000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.333333\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 4040936628858451025163914973784903415692411236688330188983321478605832192.000000, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 3579632924228517389200643038574917893197559874863080783240099425977106432.000000, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 3170990552217752005723222756703167594809406692403350119732994390544613376.000000, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 2808997820473823303788703946368605911304439885913506870584029026396930048.000000, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 2488329317130318330985719436541862849903222803301246464947479205031968768.000000, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 2204267566660412612323482533599166309382244023496130951030167027100680192.000000, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 1952633629311754900746898139652301663842221182468246520702579321073565696.000000, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 1729725623144638296126088103218847508096448362604009109863679392986693632.000000, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 1532264264247912512117690298056187822374758623666200155305091527748878336.000000, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 1357344623954196082691902722551275831684479995688580702691156575943393280.000000, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 1202393393336536010864280622535720963779598440086276833681804712136933376.000000, Train accuracy: 0.400000, val accuracy: 0.200000\n",
      "Loss: 1065131026288381217092248258511282372389730442891324127240724661072297984.000000, Train accuracy: 0.333333, val accuracy: 0.133333\n",
      "Loss: 970406444259284811166402579432176875006077390285171634561961702123896832.000000, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4630220287432776391885283810727830860424478871722792014649201763746431044157440.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4101645363344243416311028821156240700484066516030664543606927361529671527170048.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3633411294124651912761321382978474721224547898425538286999013950508110048133120.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3218629711445528452881731748755332852403844481763990215319517925326224265052160.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2851198606706516488664884489807607509878198023448062156241439565269790128865280.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2525712562081020218670811787276852668557141766227115428787313404918748325871616.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2237383229371964555812406919563025264015117546647337188634395337052987332755456.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1981968886812045653492335906005756030497997701277392296264009766657515847680000.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1755712037491954358700635957219230787703182422799680314721388187960090359234560.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1555284131403457013880178874678378621446227612245003857250647809694908020686848.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1377736597882436796419367599839436087190057442606640902468150606198281913499648.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1220457468071645367495063801627885777456069940934602010269522729837755596013568.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1081132949259835327642678487364614308805181845060461685234640852685292333694976.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 957713385802850443491689941886609378073716430606447018983886734977150029398016.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 848383105864919894829192729452310461163206751243727376473188733323045437964288.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 751533710384175632108681769753554082036331197454952953712807089199450844823552.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 665740411306273829302206932764250361340468250755679786273404695533974705930240.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 589741070988928123011520250954102946476098405126841607173438169914282484957184.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 522417634418117592941113819815464534224656930352189450005864568114039215882240.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 462779681078283863484184262963599336407215381541069493856244040698694436126720.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 409949854501869660515506281950278902086834808622110739626325973538481010376704.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 363150955146786519215208865788207287726732724640973881257833587449112530255872.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 321694506720265048660596976031986793002900487779580456497449692731251005325312.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 284970627743949738521372995081342633013271734082716406072196847254465398439936.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 252439059357009043941555394523631161097145089573574196758507923630962967052288.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 223621217363881467958934161146442346763359894215724308814851935587514093404160.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 198093151601326831397474251532310672580570628967733825323391213554585374294016.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 175479309047372690266092797995098803007962417295105027671404659219843317235712.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 155447008918894289477918120938204859098149876558807931243143378340318262853632.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 137701548478900720118945376824529912929122307904712081223293160757530495811584.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 121981867553208927520781425923491192139844700793310829268920742370175661113344.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 108056707975571711267317297776457845889153320774889813534350972165827292299264.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 95721211461406411159646994502688096094960584855417821100141047671847137574912.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 84793905860158683192667003065518881990343637549091072694975443910446377074688.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 75114035449920842494209326080842736835449723325610128595732971551866308526080.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 66539195999260768513328382875730615542004822425439303386724203764369349148672.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 58943239804761494537774977375595692308120495733674313453446087524885909733376.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 52214419884487631368406064947651138587792646234228490468976539275164030861312.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 46253746025907088607239233254794606129084525489700883913844585049184574373888.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40973528503468326889149514930293922914606025709736905349490599207013749620736.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 36296088041911346376554494526102311103081640913193549255396394675732731658240.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 32152613047096108536755750266562056980901740266655492737177356627686673350656.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 28482147292638522484104224803872438146746418721259962552356126593625083609088.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 25230693169830040546002741565599370260171883432293982049428193913226825564160.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 22350417308411306907298220664583647832357054876655296744628743897284729634816.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 19798946881787026839491282185489333947719197327268915501189267807693531250688.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 17538746244362088863623962591102833738417900810857177959981139889468997632000.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 15536564730475254484072236985999136410547332550937367229396120658294874308608.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 13762947491291847571341712574695403343167812825701973444162763224473858473984.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 12191802173392183472739101986916760485367652446762496012216482814721311899648.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 10800015064300623376140645215011993412316512599005250050466504761840895000576.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 9567111057927134773951764874828617907811493635001267577806522705429668036608.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8474952437544471576904375138352272896099613683120319865315773014504690941952.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 7507472044983553188671775996307039732384069876360136399314997453953127415808.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 6650436910598153334013358062683454345794523891674359636027791177806455504896.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5891238866670094389543671010759390995482082177714064399971799450629122818048.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5218709063889569006377667631605692538657439860360763597501156016229510545408.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 4622953662192472196190572148809027128601259875476886989890207775801749798912.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4095208278740527242921450770245527211536484645024938249805984093814231400448.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3627709051773471716343629782308549828143429117111962249750737650347537334272.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 3213578423504895581882027920486960432999191538940635497862271314022230917120.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2846723961770757399314161548143988520452108693776721040609301748025793708032.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2521748731957605877491347909812172415441039594456208343235326145151272747008.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2233871900658098727969124636360397396666502520728011286266614055037795565568.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1978858403024158684967245608192311000798886129137803744838818726442721869824.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1752956639127653860527730008352106845286910463334829002720991730482938904576.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1552843282756196564059975443283612000329926622854320275309532023432031502336.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1375574390705418602636073854423107115464374142216192639767295592906969055232.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1218542093318033980705139575428115508371020780222738442702616963643758084096.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1079436229127849920734766699987543550819925342377440134731068196163386605568.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 956210359201472739512994299783831440731178730652844494635554554495052546048.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 847051661201853455844154847540251020778602936279907125604589438954184376320.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 750354260273855768544170726370183361574679465310397012819184305985279754240.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 664695604412438118056883819487229883602805089226103958588640830018071560192.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 588815536762549616263676997658729925425886200375525099220801807713564622848.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 521597756975450984758308105721511316641086494578149328226456490405642895360.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 462053398892455574842072432719097689548114218252626111348476182295484563456.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 409306482961196445576018554087258345196246414955977052132174591331366076416.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 362581029369416487516485436298147322886553939223712014859846671449395822592.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 321189642312723801481651049443310369684371879181881557337289920413205266432.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 284523397455159828590122648869304803535995216111259295716757625349653659648.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 252042883813192938954052007521722724944600877255371481290758732002136948736.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 223270268276907385900269388827403827365052222053380175820806263587903373312.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 197782266026559624222993374285706066059526839429786533665731513593486114816.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 175203913429644601793394414191711218780287035692266182898072196791301832704.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 155203051809206532582814237467507231053744989812135740160098109864189886464.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 137485440932026237807087508560779836192494235442650541230964119518446616576.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 121790430329362924109749412110393107939974839142252950429876696702020222976.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 107887124769413988106171605714926779437832842371977338316193655949126270976.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 95570987470309115825809349415383032455382105326720967150410235465527459840.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 84660831082222148165814309867904970063346587866629181676826381091497574400.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 74996152171800581615306813938972307067403441886542491992157508860274278400.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 66434769995506683255141578238207530230271723658787851642507824942173650944.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 58850734824971844432150688456671570553804068620288889712383471363320446976.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 52132475052949004002623174601522389339328427252659223460518332801149304832.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 46181155821237416825758755004023195054716001761565415552065549133439565824.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 40909225023736336072651911512019272361004102034683689422917048966091636736.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 36239125294327720264993171453890132977627240592747516805369366459946369024.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 32102153031156064123342224675802506867222439016322513039173220204130861056.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 28437447671979771481594476170218833133988843757135728156408679273181741056.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 25191096351441970837674782372520614715644432452010618989380385191520894976.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 22315340768535784940365584099026236309896879440925350808498094719169986560.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 19767874596191217493234207774631434518595411097131802173355189897246277632.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 17511221096911017390859105962478881487929970908224043098699922959964831744.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 15512181788323559067051602528997575287327275842119681740521614575130378240.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 13741348047763725141171301979930603100289789873914712752224043996396126208.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 12172668470911892567829415120090454918969109649726092534067366934993698816.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 10783065619740735978988662472515483903832950132434469348183813379783131136.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9552096521603880057183918528685319137572509697696258642677776356023992320.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8461651924940313399856216160105298637172112196710530775968651907927375872.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 7495689887231574680020973505431986922113731511579702787000644481079836672.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 6639999775923426404371270805098524296771631194727838347754181171452313600.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5881993210440434284402533761015072346153153070552697746335133455861415936.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5210518869762437178803814093977325678596553419307895662205517224994668544.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4615698441127157277615512520851124089431464635264083132375886857660006400.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4088781296438333906657846970732966873880647034887143592870348795028701184.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3622015758469125304193624182827030950419954510919833751520204286643404800.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3208535063009216327618041026228056750876950616259999903168568099730358272.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2842256339301709112726590540318724646600747642524590254924036429871841280.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2517791122632822835746720184903443614712414558618754431020261609710813184.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2230366082591303128996176279332311374720781934022069067187593582947074048.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1975752800800992700971488748032531354646016427194287411314321317636866048.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1750205565060267833246910039933274837611148114503871463274093105433804800.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1550406264754410117592667372789989505733606634678043555924188877677395968.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1373415576876507843894119929472982145833101021048654889875573057328775168.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1216629724535990062963911814960207575189635107957302076565417906466193408.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1077742171812873259447071598533042973729978226478757309462578155629838336.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 954709691436253957897177702313302541105068932754279737931949773646987264.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 845722306095826086849983420698974324553888506218245091356704248510283776.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 749176661181719085748083543150382478291354316733414792355548479128338432.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 663652437228956299705459129284244956720981376392047773598000568009228288.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 587891455061094871525800039723497177992430595764447979341610514347196416.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 520779166240921685027743564237596224167932789071995179702304651255742464.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 461328256527226952610649050041505818922525562604784691373853413790973952.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 408664121121916681266983068995390522780948942219906459974196617818406912.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 362011998028332881008127062730884181567054145843015373425666877145743360.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 320685570234752056475730946550899736600600959634289819345163360271335424.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 284076869045482159075937219100521939408041404866014277745792332016386048.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 251647330023640751120561457483808630709606954800408311593976245910503424.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 222919869966210605379813191293609260084713187497218866429333438742921216.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 197471868352761302059633306492104718064703953643956841972484666898251776.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 174928950015272443375180732081486604481958245246963971708236634190249984.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 154959477563568658076313355684375940804278415243677006122343959854317568.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 137269672542353194259459483086688370581466211216031490758046463786221568.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 121599293545339772260519944639635128245590242761458870432107573360459776.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 107717807705584237689871924137504505388340354587825484092266339025027072.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 95420999239365293496317929912716758339989167399569467233329326604681216.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 84527965150621259678332749336865672065913935967541625194910108927131648.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 74878453898615552104028179604124572572607704963009357522395129981173760.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 66330507876964865157716513136724725536400264455007609401646964661026816.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 58758375021648865138118021788876403075321428442421786999160356181377024.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 52050658824877220940858586852756472850277613525132832861818943088623616.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 46108679538969011694717347141790665239870009249437393039391300060708864.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 40845022461295515711353482654541341713768809082851981689791589512118272.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 36182251943557565496008075042705800291008883742050168725469247305678848.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 32051772206702133540012883676852449574128869457579271913258461205364736.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 28392818202495597764784215962379473283174517738448366793895227986804736.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 25151561675937422397291153647874983864456829598044001104555338306158592.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 22280319277460138587357026247711788404039357689555701148223373238599680.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 19736851075155370236217504071993487269494699525132504747647211648581632.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 17483739147173826064312902836616382207531904621341423741907811652599808.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 15487837112537586482159971576167194108041399185282545147579260509093888.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 13719782502204110665357320521642703130992033777088039452335550649860096.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 12153564796688736250434256983527870201428292916387098097523385731907584.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 10766142775483645854622577921377496787752218832836483076670446289027072.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 9537105548956185770502592690432301154273279122945172716736028797304832.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8448372286038612987468271720938734402298377573123306427292597188820992.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 7483926220289877871985324084479297613428138666970556542975555152117760.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 6629579021192103823647629904369629004507883169036077974366636329664512.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5872762064258840512323295923352415604533490131094927449778735200337920.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5202341529250830340867143932490415193695800989820825302237547511939072.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 4608454606339217128416524270970521324634983294582927140378482762055680.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 4082364400583200253458565009787967430962680051944674334641021968711680.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3616331400167058197166666093314354485820675393420419789669839073705984.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3203499617517229186572145970996052111987932528695133618585135296282624.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2837795728278376571806996365939439135370762031248665532843997693739008.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2513839724343804612086626530566007323947678162025923157105547161894912.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2226865766523217837527924749433944829414787570314089901798325391196160.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1972652072481463802164277703497609533713838512768508291258930557878272.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1747458808503283287531160128474336078850670137573392997370972711419904.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1547973071386317454960480857284508536639019405305529126768374330687488.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1371260151070214323633939308446309381242976695096962171065018668285952.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1214720357007966633847686271454504745802502996511983350119433414639616.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1076050773135905178758032689722813977515087043901371939230759363018752.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 953211378805258330810023879867900608324160952491986402249536866091008.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 844395037267506186858198938460165630652519222353132321837441899036672.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 748000910202793836188500119010397129665953432800820063925737164374016.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 662610907182481839665020139732894998240488105753631642315044727816192.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 586968823604984589175972722336404504992117304709647384152067601858560.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 519961860195180809735724928916121580331403501687228687770878948147200.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 460604252193773206977847469277204936404602174115846272909986544746496.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 408022767399414361962135146056136978464442942737259338206206465409024.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 361443859719815364446952085189522411647914492951916068307999773425664.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 320182289242874851846011171840949350214018032039338041284317168009216.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 283631041413394089923979456572569969389619314162414580741317383421952.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 251252397012576853019384142748480743668430945013098237529058648784896.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 222570021567408083987340462388195865824040908832633929980542399283200.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 197161957814224530787442332096312452360407267572319122697557236514816.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 174654418125960254492277275716851222569570601925144369076352246087680.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 154716285581117188606693753902614220094177269270290404512533307195392.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 137054242777611353425425976926312207529503463690004343205721588891648.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 121408456729631937143051481183979320983730540820773566895145200123904.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 107548756366401102667652520516171435238325507104601317425105803935744.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 95271246398575008826597803737015833513373138805431622065303723180032.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 84395307737594467143313584539992216607204978496629267445752447107072.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 74760940340020639826271014713290796515519638703451969847842517811200.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 66226409386435338483292794121038360882665628731649837646869715484672.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 58666160166953848869406647905079531008389757575219514936647818936320.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 51968970998443157063211797852067084611155590058544752248814135410688.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 46036317000313038407419550174289544280124270673193752782535892402176.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 40780920657767152526400726811010786928201702937966251389507638132736.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 36125467849302328280705410679087013219510611198010561672995544236032.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 32001470449451866548501944721141039981167737291602606449138287509504.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 28348258774091382688663048372850856677349405789207148090890152574976.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 25112089045789889497786998721707221792254531169535768010598903709696.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 22245352748791282615259099516569112682668906137523565845161768386560.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 19705876242148804788390686393494964507173083458936657117605124898816.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 17456300327356425291957748170214088232147573174291274511042977202176.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 15463530643062437696114624759471357563347170545036356392492319375360.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 13698250801413848702143530147019173260493760081213871341861844549632.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 12134491103596641229267546048996166977568011124060894930971052212224.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 10749246489783073450693142389302691667298443916823422401176768872448.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 9522138103003435841142251554077770058525374499655415001448099872768.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8435113488080373248305001617151242940245111983055217420467330613248.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 7472181015139156578893244874342027931742581255515245586169511018496.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 6619174620697653898209296325047099757731609582264080458616777211904.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5863545405353370833259420041317225782189088729309278373666166407168.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5194177022182399846663482034619366300656720047093492591663215804416.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4601222139959138921648784142090011461535517851364534861523142574080.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4075957575345552380366322049787504592872035904830308690938417905664.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3610655962844760562748655293748034155092138423702764921457165205504.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 3198472074607200946026830377778101629856979097546539943582859526144.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2833342117697059907948920665760101928744798291755666814654260183040.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2509894527343011668358571924520253938155522344826459417015796891648.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2223370943819057263452310252507575147955517842904545549109505818624.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1969556210416513054218881533433094368169179985154695826221354188800.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1744716362680840599549323342909961545574358730759128712345710231552.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1545543696649573617068956015134754715270212251208998201990534135808.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1369108107969406402911355864094966023748948267193842357409257881600.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1212813986023825617972280782191261868225706346045426963161764855808.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1074362028924503608308434924156090398772459940711931202020713693184.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 951715417612359706040610659212264722644449858340326049736613167104.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 843069851442708786103597339472362335098930403176658177272580145152.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 746827004436668052898214184367404925754877995502854900047690072064.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 661571011703706995258901154910383420556862736304381738575256879104.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 586047640118217124750260710712058836804928795266887695576588091392.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 519145836822050083912183045707001819699958524216929754404190420992.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 459881384106078659892338910892537779532954143118421751781010702336.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 407382420211560210454252691630727607408031049774735321938771574784.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 360876613042347028176510331920134708689323062514327370286208385024.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 319679798095569143628996344994920104810475501130520143416774361088.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 283185913459101770963872113464725565659031045495547289017616695296.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 250858083805757298357157431379096453675058996103466584356555849728.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 222220722217472929717537094961450836529958134813672083259830304768.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 196852533646443803864076167883691030383802610532050109661288857600.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 174380317084476435822218359327179802637104355823094839663770206208.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 154473475261931808107662429163711270576884898684471928834834300928.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 136839151106365939165077530023876480498314588764349902577402380288.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 121217919411471870861407726722627463899040528011562273620705148928.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 107379970334838732120354846017348744903850679635481110302504779776.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 95121728578519217380604627687714975635189064204250623083613782016.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 84262858515894630999328964044566515428946685852373469562564247552.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 74643611206126460822878861780692702924855625453377565587199229952.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 66122474267121836647016978451801588581978866459495967667148292096.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 58574090033405792731480727938476617515349681169633388249533644800.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 51887411372134464964552095990467245391362372923844424804369170432.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 45964068026761387620994577126107958656939243366227194814182457344.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 40716919455021175592741249101215374376019201953860464961671659520.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 36068772871483679648186206881836184173949461981296015026029592576.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 31951247635317955449309106306705913438812836757658332102450479104.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 28303769276845308038098341339638549090186880940558962163475021824.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 25072678363625979058886801269923257286737622910804142054455640064.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 22210441096271742259745303807633394353030152645276180664142528512.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 19674950020760984660356870560574927636552673597953219952560308224.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 17428904569771117126007026301192882706151343502820671176262549504.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 15439262319937496030834724876304487275294799590577390726609371136.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 13676752892277275406892081289548757780082182771017822992857038848.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 12115447344583501657646653564190327961570874371896712185086214144.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 10732376720958275085534034823791579835568736455171912795183644672.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 9507194146823047790428257631160820036710285920512497708955598848.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8421875498358012110786860286269389197660989237042857219968729088.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 7460454242805647469182809809136261855638649044399379630813872128.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 6608786548773883910335266942085118206296762287956623143943012352.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5854343210987838166947929078908815196616303872399649200322641920.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5186025328416460471541266567972246009436538974172681906386108416.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4594001024145445511254383622533092828391748259973375408543367168.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4069560804920655575199187092723668706613185965677081548753469440.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 3604989432501728810732351085709860576450610751558225676065570816.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3193452421876890690855462173809632675390340901044326352560324608.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2828895496571332996804291160462695679353376330886377986618032128.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2505955521898196468380544613849086850399123943377131821277904896.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2219881605857586609748737703189549246213552525089457909027307520.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1966465206969083990517295301501589116340638231841983709073899520.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1741978220827712221554117628267312903965210807037862887498448896.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1543118134551255073270223530967623392606523044901983965688102912.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1366959442265298135581094036613563484476300910869826016787824640.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1210910606880817564017894370114583288052072935591091247293399040.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1072675935012774438278965886265939109351878074018804117591293952.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 950221804167233278893066356167126045302143315294638671210217472.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 841746745352387694985052763956285357023789438623490911435227136.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 745654940987482137244845804374161816395995527849178810225262592.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 660532748227356406687382737232970314332477381064078816985481216.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 585127902328362552640288303609087308395153515590283880824832000.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 518331094108514872562495131284010451937100398557775004419751936.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 459159650480928639085713945356040272280266163446639569741545472.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 406743077978708039740243316372321924466366956859593036295831552.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 360310256596610286321209891573972316517029360400330950451396608.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 319178095553260009781453528713733766487482013439065730435776512.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 282741484084537116363407608990576158062036991238708748370313216.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 250464389430467126134304628253817932848852439477493473776500736.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 221871971054733102342091114073419040273183111532185457388421120.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 196543595086113312927537143735630901468711556262563225456869376.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 174106646214652564657490770734265521150515086502443958107373568.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 154231046007033924352101667216915866056496690153828826612760576.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 136624396998016068295914172626244892726594152287386630218579968.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 121027681120830960332545202912037452185284417024781871701032960.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 107211449194525813098404907736801139032547416252748160791740416.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 94972445410358523352626424752962921465496395741690449667031040.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 84130617158788278925478595657029371784819313625398831942205440.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 74526466207498695681282042756925141846511789065136093739876352.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 66018702262631089635495647444946943248217140764875880990244864.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 58482164393880659145787555092292480838674734025477784252448768.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 51805979744755102652402952756928717928814204964265647352578048.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 45891932440086006492462391790552735553400380044611115770970112.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 40653018695175629296361972561027361795956544377549873433542656.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 36012166870243078664782629137249401819829636542566959845212160.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 31901103640407787499215024963504160555318718689776751102394368.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 28259349601008049657286214675335977674615798922767639085318144.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 25033329532225097212319606371785573721749399753618806475325440.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 22175584233779369705468646629690061476372550123678366718492672.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 19644072334701303121694175098288582718721625052173885474078720.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 17401551806836436318662698959900870452675762065807257190268928.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 15415032083296223773287746563313453669551599584512985538756608.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 13655288721762076458523401997370402917110315660451358288379904.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 12096433472671045410339672294803787120035460632324457103360000.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 10715533427393903015602391653654256808525527501411469586595840.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 9492273643550390331902514550821945199393569729353918841880576.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8408658284215273531993710362893665428680108985650571397562368.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 7448745874361054165142385641986356748599108356915630276870144.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 6598414779794896170304498164420673159282211140564211747258368.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5845155458461714780619795271447444363225106849991012779032576.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5177886427843931538721790012607199541065472212055362390458368.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4586791241084660822216003005637374348816950433742314048323584.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4063174073528578205009156830423901587292082060786268421226496.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3599331795159431923143579411356058924618953128955730605375488.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3188440646943526549277400978190703002124261682462824312340480.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2824455853932006110136166085963894271642084047986760792145920.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2502022698292389490377675642668220113922609222764064644530176.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2216397744031099699244268951339575165188917199901226778492928.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1963379054514108113944043981267792836616984743604741705039872.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1739244376189287135410452076561059709803770128323188589854720.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1540696379107840629842719336869240351513198362461038606024704.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1364814148657433921142033504154701292541147077470704487104512.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1209010214883574112934051259704553914022864212971218779766784.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1070992487241361778380527105459207800945920037032729182732288.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 948730534785344720534226452548525714707370283261676320980992.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 840425715732625951616506901994389385517847179631288037408768.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 744484716963920492735441614292616635559430329750074574241792.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 659496114192180513160481447626887662876261833950861528662016.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 584209607966557541545126837196044455785691759847298077556736.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 517517630044719323447059709072192491900446805514493160849408.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 458439049537908913837243641256875197880841874579714952134656.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 406104739123690620950825136616638386230755635170010474741760.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 359744788985483663786889029070967400909063389204124874571776.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 318677180378318051306507176769189333722514665965328483221504.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 282297752193355626916751809698436337149249781107693520420864.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 250071312915517702741683810616167141107981302611715444178944.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 221523767218868503870690767185156052333926434163081009430528.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 196235141371125024773828041164327332483552281606264809586688.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 173833404841380992808055880768024635873047454200058536263680.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 153988997218384516097665542803319636854202456180663164862464.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 136409979922793608640331329097962193942404259989489591517184.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 120837741388417932559137493432851867657115836018742737764352.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 107043192529744492205597352716156896573353001050957072564224.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 94823396525832380745719400300512556104868624709510076825600.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 83998583340054508953447839057790092212366584126076109193216.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 74409505055156990198555913750203950464594736700008521793536.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 65915093116972125575012565918002513814110474467473530814464.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 58390383021610838961003597040804144589727613804561955815424.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 51724675915424633548783073093912577201661039196830900944896.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 45819910062338560328331641600848600365788580883471221653504.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 40589218220596325902703498670604286930427559901971041222656.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 35955649705941504410552484289445937492952238523817014591488.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 31851038341023194681236329912580803421852004042578493177856.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 28214999637002539488471701973964221997779164967498047029248.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 24994042454519218569113997647575590620447037140504858853376.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 22140782075327205409026697147365853929160845199181770391552.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 19613243107798825573685748680577656905271274270273518436352.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 17374241971076948079552494024810799801924988827987072778240.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 15390839873366038786136211836506118144754532425234225561600.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 13633858236919160875562448450466612213120247468523461279744.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 12077449440954727769622139530101961496573058396899021684736.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 10698716567539920025658791468253985296211943078468639522816.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 9477376556378683765663396196854282108334610188749938622464.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 8395461813047151011744775732819955325442707194018588000256.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 7437055880922481857485759733291888961961778423577052184576.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 6588059288174984400713030866998472332577362904521042296832.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5835982125110117175291493772200247605241670963818380918784.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5169760300387292628840645910450293931091856804470239264768.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4579592772991267225729647356780898160456197395434470113280.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 4056797365414153032772518428677569282375216977088547389440.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 3593683036861274980683506501149044983982358270246530318336.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 3183436737443761189316855991214194225269244292649174695936.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2820023178827106953826008223495592565901746750058919886848.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2498096046823869791794956672283094769915704681990325272576.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2212919349745402484122578792994430646914830760995654205440.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1960297745438482829991192456198182848615635186465172881408.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1736514822021556276854176656251142843979627192596727595008.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1538278424345200814519534016246442112001095468378581106688.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1362672221853675105213155817702431700604159197781034008576.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1207112805344096594132036666410439071123154317215784763392.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1069311681457436195599328374996179392254635342534822330368.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 947241605787942813108653546864318935230044898334045372416.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 839106759324629710347164029663414622648459174562439888896.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 743316329479205388439405009236122446190064053205474476032.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 658461107040948915149581652108256128060082654161317920768.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 583292754767499300924767211155067286206996824415340068864.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 516705442623962755100319015907036658733145883061633679360.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 457719579499398283645465243519053943536520735274091675648.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 405467402071815911992948985016249229986037594797035749376.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 359180208814038045170199446308328887136709402951495450624.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 318177051335056089520852202742465483043745174452774633472.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 281854716690933229413632028971533294535948451839790284800.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 249678853291244503841852395337714700642357898389028339712.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 221176109850909439597456301221170091766108018962451136512.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 195927171740567228592877807481386927296737840845167788032.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 173560592290613879244739208284916958634739938154984243200.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 153747328298883400465735937670747010709033686564434083840.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 136195899351761903174165698592634307431867846045986717696.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 120648099745678517909475664527600406822883410926003814400.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 106875199925429200905694123831015558039009826867859423232.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 94674581557258177772865747030637826313224266735920611328.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 83866756733984520473272895762452071029640348720324149248.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 74292727460574775775182115762434975270827713995395301376.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 65811646574555803813850123429345818831401240598350397440.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 58298745690184626824208014113114954821596733912534482944.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 51643499683578013405514370582265668136416156726809591808.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 45748000715849974180489893079279604665094778141167058944.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 40525517873896525064821567346698107404927538283226857472.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 35899221239159088794628008910868374936779296871370719232.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 31801051613660161716488231403825121045281481060679417856.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 28170719275423660053597898759596429536509059720074493952.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 24954817033592666855124661107967672714896227696237346816.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 22106034535063237650688855184760341800515756074920312832.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 19582462264002222643640771064520106314822241315484336128.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 17346974995123164616200994349089790139009849791743000576.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 15366685630468179423561948785826118845739715139202973696.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 13612461384882545671533236486316282123496778660023631872.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 12058495202603617814069549812644075928820561554303877120.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 10681926099911513829902760716222097552190583028597129216.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 9462502848558918988858955995039538317684331251962478592.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8382286052299812492483089182587203648670005128853454848.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 7425384233652364643691950167544874105007660973191856128.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 6577720048368618167591338748214699927855208686908604416.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5826823188303722668777849769697014455816811755643863040.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5161646926000533317922397506953179067392005618052104192.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4572405602107658613604227943121064453578854761488187392.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 4050430664846939215320650107361914737006135905183858688.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3588043143672566478014270333240217398691781362212405248.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3178440681033659016027068718375520477713628832366329856.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2815597460321849935653746413038252602983550708577468416.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2494175557806139515800357658175774423953305506594947072.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2209446414419785355749514559268186963901881438957469696.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1957221272141050271817755195398145586925212809543286784.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1733789551591094683083696304593624933997088128978911232.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1535864264298582806060855513028330245821332856181358592.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1360533656570192421623552371708760658132360967902724096.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1205218373581742853148834730468056402983407898811432960.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1067633513514688946610504784907347719503995953225924608.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 945755013502049471185004814449393520435724419969581056.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 837789872874719859974147917129459018336615416813584384.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 742149775651089867373933704878823210595404274873663488.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 657427724220444951505902640331925104522728735414157312.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 582377340469439932236104597416617590834247567035858944.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 515894529842693138151577569770219361039102229832794112.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 457001238590565144256744574254673999365146847769264128.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 404831065250863155749356653011215780561845680015933440.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 358616514689533956347394884043640115714017420411666432.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 317677707189726509376874342762259737960158068937326592.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 281412376484363806792531678016652268100222814955503616.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 249287009589505220604137505502865834570594650865795072.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 220828998093234113350422865439232316277466978200846336.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 195619685434722230995201388043200665717957283069034496.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 173288207889361119748715844161149440271798612290174976.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 153506038652367365286266404618447630054247408548708352.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 135982154756814397140062830919479878867542246707691520.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 120458755724793313504267315491027207321899720677261312.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 106707470967165924376210593669684272260719786382589952.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 94526000137530415104638884717932174082621552214409216.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 83735137015380735648964937646256124004455435286347776.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 74176133135678123279032360211729400375659639001317376.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 65708362380194157841493213756255211870997517170638848.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 58207252173545669245034915203149213435685042021990400.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 51562450848964940398602643681878103121589302718365696.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 45676204223230094943296874059016167089014450144935936.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 40461917497936428357129269770976730386060357939494912.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 35842881330694754238643392216017991469838744896405504.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 31751143335008447911210925765783341649948412466954240.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 28126508407038014256823092041352725022607328839467008.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 24915653172681860098453122448768829048888854688301056.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 22071341527270177609117490165200960228718279697367040.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 19551729727379488264656360108505088486864230352420864.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 17319750811711292692643243501025499251003639428284416.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 15342569295017517569150707109555008841063428259840000.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 13591098112869223745916063370306075109663859806306304.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 12039570710860295843321830909379747527935459558686720.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 10665161983088962129714080788842632884543566588674048.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 9447652483399745505599902060029452815208918942744576.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8369130969470512843171144063136498660001930247405568.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 7413730903758394396279064155396800790546671229468672.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 6567397034870352276346703407249167360019593607249920.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5817678625448726962972456399305214660654590983143424.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5153546284669103513451937875987024628330744992759808.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 4565229710704099763754959578505027540974135125475328.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 4044073956121190154661174643099908232448615953465344.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3582412101680489201536448499002269639828934060146688.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 3173452465388651160321036761194944904359264150093824.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2811178687498612744375965867660933581518825515384832.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2490261221567906403315119787558434850717651750092800.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2205978929487006816804851496207577267414166669361152.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1954149627032588181295245794877173110244367667298304.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1731068558175045909238277214127919238085789154803712.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1533453893012593771488324664199488278980810332176384.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1358398447531445815861017883871900655080790468591616.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1203326914923217474827573316278512065660475169308672.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1065957979273314861848511487068299995002248636661760.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 944270754260451598730707676734519437304614963118080.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 836475053134323555249466406347594051585232739500032.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 740985052601850039595206538731935677697001854599168.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 656395963181459246917928048578618869676669908549632.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 581463362814182060757165633677145888005982917754880.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 515084889700503053885007456438257544959571007635456.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 456284025039364477697775748869466275859691686854656.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 404195727091079592674064856865732671326200201740288.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 358053705221417445295575482235028791064111930671104.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 317179146710517390736402413016928165261400476745728.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 280970730482456624340155461085217590329149292019712.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 248895780843676622322128010783570815208005300125696.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 220482431089566785256429729015232366436499358482432.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 195312681695064733409202821962061579885850795180032.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 173016250965688679517594320498162438955760210673664.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 153265127683609039695009941066395997782761638199296.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 135768745610673216665616626392519634500846767570944.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 120269708858677435202345000805683893579981288112128.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 106540005241190979782512301969600536001559968874496.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 94377651900119680291463923581263204463167762595840.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 83603723859555807743642668101737657453349745721344.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 74059721792845316732070677864607651048518167035904.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 65605240279099569789741258442639757995919234039808.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 58115902245992349043437131505284638752836123885568.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 51481529211649344457723805178880657301181067952128.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 45604520407367021360795913132293163250053208342528.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 40398416935822876720247702744355684647750978240512.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 35786629841565869472406273448847148655805810606080.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 31701313381951381544927663091861567756871470678016.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 28082366922783604993279502415151145245209283002368.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 24876550775175064020648891644539817133414794919936.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 22036702966365264908243384703443353216470896082944.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 19521045422117776846519464913899961534457107709952.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 17292569353683101650138143854726162315353075482624.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 15318490807522475565507318244805215089762020360192.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 13569768368179011069042381988832218792990741626880.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 12020675919040689315011152360464879181880929288192.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 10648424175717557087120149691781605168215815618560.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 9432825424267417849600498962328424592253841833984.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8355996532107520446110552263276546885390503510016.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 7402095862493453237614349502744949844416185499648.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 6557090222214763526328792609865281626228085751808.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5808548413986779365372846486106207275128664883200.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5145458356409860172978139025111827818490403749888.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4558065081078674754767629344165286572681053863936.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4037727223555793446959889507165205970080938065920.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3576789896994055051171427041708840313276952739840.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3168472078203513570747418197242031168822888628224.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2806766849456906696665034621335804414676418166784.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2486353028453054268535048714521640003742845632512.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2202516886393271176860265473165801620752375480320.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1951082802535778288193648714801676986059155570688.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1728351835061099620022964969141591619194832551936.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1531047304541188618103201979046908132052478984192.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1356266589470175881566331060257100462928999481344.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1201438424702557920100584230477398459857892278272.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1064285074600007282893422346208974563796083277824.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 942788824401690530977677542103144722056804827136.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 835162296859965102414567123482836086399703187456.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 739822157458278190749668104563464333011938443264.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 655365821378782106855624881664625986900259241984.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 580550819547071507160876590445869237713296687104.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 514276520200124134418486957478881059919928229888.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 455567937076530909766683325969632736866069381120.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 403561386025175154902772768416132331656085241856.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 357491779021316961446641886248279189670923862016.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 316681368667550311636406287777242250959812296704.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 280529777595732864188289818392427505278668242944.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 248505166088652448290114537855937033716950368256.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 220136407984975722728188254192294456339642449920.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 195006159764259673337586667101857666639526363136.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 172744720848717350709476356049946212940549980160.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 153024594798314846178397227098641924188677341184.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 135555671386888085590938073898444765907380076544.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 120080958680978967421824077348040792641565097984.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 106372802334390003658973986582749647998503878656.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 94229536479071691377138316801927926066182094848.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 83472516942331997461978553355313357347318923264.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 73943493144905974370214931242669941015034462208.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 65502280016884343932450044405667825704109080576.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 58024695682177259435636340551042527615504089088.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 51400734572008968872340358422909398657062141952.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 45532949091426931235213650370450537628928311296.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 40335016030908933540948898369384301785035833344.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 35730466633007978841637969437862993745865080832.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 31651561631565502944663116698555419543268753408.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 28038294713769609186861216634878020285894754304.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 24837509744612182459988760980850163382084435968.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 22002118766900050660317796780529386599781236736.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 19490409272523240910849984859235600602744487936.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 17265430553985765110330553340931098810280574976.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 15294450108584805541506793433629221511403405312.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 13548472098194425950171303901858780332767051776.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 12001810780534025996869787477996685159951237120.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 10631712636507481627051593841214499612589555712.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9418021634585663787120371345915785276366520320.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8342882707810023150289867716100676320143343616.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 7390479081155526239972817909061085094005964800.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 6546799584976398347507930968517171101644619776.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5799432531394938307752611318892010273264107520.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5137383121271027724813094757820571949213941760.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 4550911695557254532591573100922100654956085248.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 4031390451494261992861275845741621596213215232.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 3571176515744073197303948129376301875594264576.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 3163499507192334195464165667999659455028396032.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2802361935313347705143648009865487917927890944.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2482450968820621842750414497387124798496178176.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2199060276598202972246185743852219965953277952.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1948020791085198864028730749209220184889360384.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1725639375547485555924060312995414086606913536.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1528644492947650601066284766945367972372283392.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1354138077127388825026522582144704390990135296.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1199552898261125195789030976716772079222915072.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1062614795367946977444034362719107485009969152.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 941309220270053882030582957252668406399762432.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 833851600813259756178183871453994361989103616.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 738661087351675837576227184990062193418436608.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 654337296271199556787356650960498396229533696.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 579639708416992212403316694897358155089444864.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 513469419347422942205906510350087833157369856.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 454852972935576802674250995064155104597770240.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 402928040488319938761151238562707239042285568.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 356930734703039433696294705424641193806921728.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 316184371832877245182079981412301570809266176.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 280089516736424216610384969913791014538051584.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 248115164360841235153594925144734707772030976.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 219790927925870234950969347074718263628791808.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 194700118886160696429862289033821780231323648.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 172473616868620517675388434550547177768222720.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 152784439403124132934052163110050553367887872.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 135342931559834967003777246900177628798386176.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 119892504726077644765721252469916135252295680.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 106205861834296972139459019285239563322130432.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 94081653509006663255613800988342923833638912.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 83341515940040362497544893449977746671271936.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 73827446905140350180690471199721844440563712.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 65399481339560075937789279960421797019516928.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 57933632257106637707312554210031146444521472.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 51320066730734781783855696913268444059664384.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 45461490098853444570871436062490298253574144.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 40271714626793504972599004407452454243794944.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 35674391566474335232050273333280051948421120.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 31601887961120221385598580346822832425009152.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 27994291671276128236141638555654495307563008.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 24798529984684488188102052970073458835718144.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 21967588843560193999463333856996322770419712.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 19459821203020805084682116616112352968835072.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 17238334345671697099879844620432679286865920.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 15270447138899482383573642039105709376798720.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 13527209250380573408269172722108976253108224.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 11982975248802652299245414525324608915111936.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 10615027324233726145629911742215587421487104.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 9403241077835619554474335714465291192762368.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 8329789464228067662240607004211702206038016.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 7378880531087653694594439496637193390129152.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 6536525097769706840568226050453753630294016.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5790330955185605746665833956139500516147200.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 5129320559332136882099014703245948375531520.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4543769536493444024388584516388651075108864.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4025063624304666143022831375578491877588992.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3565571944083126559277939256148893020192768.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3158534740088477949829292974878836704411648.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2797963934201632664831380196812818772656128.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2478555033044777922133429945897985614282752.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2195609091574836264609938000899095182442496.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1944963585127297445418717727410250829529088.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1722931172942946244325046515782098706497536.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1526245452304583746976089131911547629600768.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1352012905252345201983720276647666696323072.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1197670330947590973775849585854784397639680.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1060947137456788718121932120794188631506944.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 939831938215567461146871387655123817725952.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 832542961760905602109071503880856002363392.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 737501839417846878322821610701232466296832.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 653310385321484934219317867926441424846848.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 578730027176361573973145292867774835589120.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 512663585151395382937823703864665278775296.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 454139130852786182561495088577415651262464.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 402295688918139689844192903801816645369856.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 356370570882567905003335512515551940313088.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 315688154980476899362701628095214508834816.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 279649946818468941741914311831949622116352.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 247725774698163596238829810700180875378688.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 219445990060000108364802772303229969498112.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 194394558305808102538656281469893843353600.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 172202938356622741291490044745045889777664.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 152544660905607324444065311776582045532160.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 135130525604714719329849646862273569882112.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 119704346529084179703935317458982948306944.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 106039183329093275457776932629040097918976.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 93934002625118153684271926726882590982144.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 83210720529519868269331527527868441559040.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 73711582787278808657642775736991451447296.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 65296843993536925633132665303926686351360.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 57842711746139915105717108468741700583424.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 51239525488830625973856502876069263572992.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 45390143253367329424919001577445354635264.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 40208512567320956242210227010914127708160.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 35618404503635654089442152439273079439360.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 31552292248077629243542347446004744192000.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 27950357686753826716468453646119318061056.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 24759611399234407681162828745980556345344.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 21933113111165242656147599618790452625408.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 19429281138154028479264889385395773505536.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 17211280661898375676618374736214992355328.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 15246481839254580592693921364254199382016.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 13505979772285015076819692527466074603520.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11964169277381979164136286781869328957440.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 10598368197735977736111385063770736820224.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 9388483717555740630816513234182114115584.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8316716769062471041863983142995316703232.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 7367300183677854515938453758868619001856.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 6526266735248975929593765032432548970496.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5781243662906478106909213140712465367040.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5121270650703985672785556755026834096128.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4536638586268545557864201505144718753792.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 4018746726379618459932175409233767956480.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3559976168185527608945857025772628213760.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3153577764644567396234427676472666750976.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2793572835272514112462433674238156079104.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2474665211514799021898264589722974158848.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2192163322809583712351607439170325184512.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1941911177120378248070346359253099347968.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1720227220566728829422172241796586799104.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1523850176693892856776231034327505305600.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1349891068602545269763954705039519383552.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1195790718117927357231664117225055322112.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 1059282096752657338636906219255342563328.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 938356974593983833775977817632405454848.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 831236376474674801069534341592294359040.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 736344410797090119167744523372073058304.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 652285085996393594193812638067048054784.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 577821773581124209867671937100382470144.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 511859015624162046640669583075239264256.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 453426409067211245599489390721156251648.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 401664329754712411147480589742672707584.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 355811286178057219397138890636547588096.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 315192716886252200558097401074176491520.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 279211066757510393573789849074026938368.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 247336996140050233509328713343035244544.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 219101593536452100337568632089572540416.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 194089477269427107799138790416186343424.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 171932684644998513851020144922035486720.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 152305258714264753466636868513291042816.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 134918452997551812652393841034155524096.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 119516483625838962424321775127280746496.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 105872766407606432343940902125872087040.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 93786583463172239538937051001695240192.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 83080130388116719469781704255666651136.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 73595900505500891156495469888487292928.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 65194367725622954052611582256429924352.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 57751933924988983481682613208317165568.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 51159110647612639813735932260838801408.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 45318908378965979269071702182424739840.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 40145409696580712464450102314791862272.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 35562505306379765700505398908238692352.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 31502774370092097251197856751714041856.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 27906492651823780186951290298541539328.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 24720753892255291343672994354203459584.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 21898691484668427343117542581497495552.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 19398789002584875106549805328078209024.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 17184269435928168749027486940549611520.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 15222554150531076470670092195573268480.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 13484783611537614670050167647954272256.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 11945392819880325806972568799973212160.000000, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 10581735215918519810139937336371183616.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 9373749517341693580425134201886474240.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 8303664590064737209374352903550009344.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 7355738010359037816586783555558834176.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 6516024472108271801811481778962038784.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5772170632140481604060275238061998080.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 5113233375528583800020258178564358144.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 4529518827291507736833546189728120832.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 4012439742136222020043272577819344896.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 3554389174247284182451217928598585344.000000, Train accuracy: 0.200000, val accuracy: 0.133333\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input=train_X.shape[1], n_output=10, hidden_layer_size=100, reg=1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=1000, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.304508, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.307905, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.246736, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.235685, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.188492, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: 2.311772, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 1.435931, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.225049, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.100659, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.355682, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.822286, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.009299, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.261461, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.466319, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 0.551693, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.312026, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.629623, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.399574, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.103834, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.160315, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 0)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=0.01, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-167b1f217e7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Save loss/train/history of the best classifier to the variables above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best validation accuracy achieved: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.308022, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.184943, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320917, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221517, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.246963, Train accuracy: 0.222444, val accuracy: 0.225000\n",
      "Loss: 1.770575, Train accuracy: 0.263000, val accuracy: 0.264000\n",
      "Loss: 2.006900, Train accuracy: 0.297889, val accuracy: 0.311000\n",
      "Loss: 1.780271, Train accuracy: 0.342778, val accuracy: 0.341000\n",
      "Loss: 1.994106, Train accuracy: 0.402556, val accuracy: 0.395000\n",
      "Loss: 1.701707, Train accuracy: 0.439111, val accuracy: 0.439000\n",
      "Loss: 1.808624, Train accuracy: 0.489222, val accuracy: 0.490000\n",
      "Loss: 1.357587, Train accuracy: 0.530778, val accuracy: 0.527000\n",
      "Loss: 1.440596, Train accuracy: 0.562889, val accuracy: 0.559000\n",
      "Loss: 1.216439, Train accuracy: 0.587889, val accuracy: 0.578000\n",
      "Loss: 1.130406, Train accuracy: 0.610667, val accuracy: 0.592000\n",
      "Loss: 0.977987, Train accuracy: 0.634778, val accuracy: 0.619000\n",
      "Loss: 1.444767, Train accuracy: 0.642889, val accuracy: 0.627000\n",
      "Loss: 1.107608, Train accuracy: 0.668333, val accuracy: 0.651000\n",
      "Loss: 0.859170, Train accuracy: 0.676333, val accuracy: 0.655000\n",
      "Loss: 0.832616, Train accuracy: 0.684444, val accuracy: 0.668000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5efe42c490>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 0)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)\n",
    "plt.plot([i/100 for i in loss_history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5efe360f10>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.626000\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
